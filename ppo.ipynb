{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python388jvsc74a57bd08420e9e93c695d97be91f5272eab9214f2b8a154faa67cd6133f765f4ca85a58",
   "display_name": "Python 3.8.8 64-bit"
  },
  "metadata": {
   "interpreter": {
    "hash": "8420e9e93c695d97be91f5272eab9214f2b8a154faa67cd6133f765f4ca85a58"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "C:\\Users\\franc\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\gym\\logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n  warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    }
   ],
   "source": [
    "import gym\n",
    "from scipy.stats import multivariate_normal\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.distributions import MultivariateNormal\n",
    "import numpy as np\n",
    "from collections import deque\n",
    "\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "env = gym.make('CarRacing-v0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN_Network(nn.Module):\n",
    "    def __init__(self, output_size):\n",
    "        super(CNN_Network, self).__init__()\n",
    "\n",
    "        self.conv2d_0 = nn.Conv2d(1, 8, kernel_size=4, stride=2)\n",
    "        self.relu_0 = nn.ReLU()\n",
    "\n",
    "        self.conv2d_1 = nn.Conv2d(8, 16, kernel_size=3, stride=2)\n",
    "        self.relu_1 = nn.ReLU()\n",
    "\n",
    "        self.conv2d_2 = nn.Conv2d(16, 32, kernel_size=3, stride=2)\n",
    "        self.relu_2 = nn.ReLU()\n",
    "\n",
    "        self.conv2d_3 = nn.Conv2d(32, 64, kernel_size=3, stride=2)\n",
    "        self.relu_3 = nn.ReLU()\n",
    "\n",
    "        self.conv2d_4 = nn.Conv2d(64, 128, kernel_size=3, stride=2, padding=1)\n",
    "        self.relu_4 = nn.ReLU()\n",
    "\n",
    "        self.conv2d_5 = nn.Conv2d(128, 256, kernel_size=3, stride=2)\n",
    "        self.relu_5 = nn.ReLU()\n",
    "\n",
    "        self.action_linear_1 = nn.Linear(256, 128)\n",
    "        self.relu_action_1 = nn.ReLU()\n",
    "        self.action_linear_2 = nn.Linear(128, output_size)\n",
    "\n",
    "        self.value_linear_1 = nn.Linear(256, 128)\n",
    "        self.relu_value_1 = nn.ReLU()\n",
    "        self.value_linear_2 = nn.Linear(128, 1)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.relu_0(self.conv2d_0(x))\n",
    "        x = self.relu_1(self.conv2d_1(x))\n",
    "        x = self.relu_2(self.conv2d_2(x))\n",
    "        x = self.relu_3(self.conv2d_3(x))\n",
    "        x = self.relu_4(self.conv2d_4(x))\n",
    "        x = self.relu_5(self.conv2d_5(x))\n",
    "        x = x.view(x.shape[0], -1)\n",
    "\n",
    "        x_action = self.relu_action_1(self.action_linear_1(x))\n",
    "        x_action = self.action_linear_2(x_action)\n",
    "\n",
    "        x_value = self.relu_value_1(self.value_linear_1(x))\n",
    "        x_value = self.value_linear_2(x_value)\n",
    "        return x_action, x_value\n",
    "\n",
    "agent = CNN_Network(env.action_space.shape[0]).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "CNN_Network(\n  (conv2d_0): Conv2d(1, 8, kernel_size=(4, 4), stride=(2, 2))\n  (relu_0): ReLU()\n  (conv2d_1): Conv2d(8, 16, kernel_size=(3, 3), stride=(2, 2))\n  (relu_1): ReLU()\n  (conv2d_2): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2))\n  (relu_2): ReLU()\n  (conv2d_3): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2))\n  (relu_3): ReLU()\n  (conv2d_4): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n  (relu_4): ReLU()\n  (conv2d_5): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2))\n  (relu_5): ReLU()\n  (action_linear_1): Linear(in_features=256, out_features=128, bias=True)\n  (relu_action_1): ReLU()\n  (action_linear_2): Linear(in_features=128, out_features=3, bias=True)\n  (value_linear_1): Linear(in_features=256, out_features=128, bias=True)\n  (relu_value_1): ReLU()\n  (value_linear_2): Linear(in_features=128, out_features=1, bias=True)\n)\n"
     ]
    }
   ],
   "source": [
    "print(agent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class OrnsteinUhlenbeckActionNoise():\n",
    "    def __init__(self, mu, sigma=0.3, theta=.10, dt=1e-2, x0=None):\n",
    "        self.theta = theta\n",
    "        self.mu = mu\n",
    "        self.sigma = sigma\n",
    "        self.dt = dt\n",
    "        self.x0 = x0\n",
    "        self.reset()\n",
    "\n",
    "    def __call__(self):\n",
    "        x = self.x_prev + self.theta * (self.mu - self.x_prev) * self.dt + \\\n",
    "                self.sigma * self.dt**(1/2) * torch.normal(mean=0.0, std=1.0, size=self.mu.shape, device=device)\n",
    "        self.x_prev = x\n",
    "        return x\n",
    "\n",
    "    def reset(self):\n",
    "        self.x_prev = self.x0 if self.x0 is not None else torch.zeros_like(self.mu, device=device)\n",
    "\n",
    "    def __repr__(self):\n",
    "        return 'OrnsteinUhlenbeckActionNoise(mu={}, sigma={})'.format(self.mu, self.sigma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_torch(tensor):\n",
    "    return torch.tensor(tensor.copy(), dtype=torch.float32, device=device)\n",
    "\n",
    "def get_action(state, action_noise, noise_factor):\n",
    "    probs, _ = agent(state)\n",
    "    probs_with_exploration = probs + noise_factor*action_noise()\n",
    "\n",
    "    return probs_with_exploration\n",
    "\n",
    "GAMMA = 0.99\n",
    "action_noise = OrnsteinUhlenbeckActionNoise(torch.zeros((3,), dtype=torch.float32).to(device))\n",
    "def rollout(noise_factor):\n",
    "\n",
    "    state = env.reset()\n",
    "    action_noise.reset()\n",
    "    memory = []\n",
    "    timesteps = 0\n",
    "    done = False\n",
    "    while not done:\n",
    "        env.render()\n",
    "        state = state / 255.\n",
    "        action = get_action(to_torch(state).mean(dim=2).reshape(1, 1, state.shape[0], state.shape[1]), action_noise, noise_factor)\n",
    "        action = action.cpu().numpy()[0]\n",
    "\n",
    "        next_state, reward, done, _ = env.step(action)\n",
    "        memory.append([state, action, reward])\n",
    "        timesteps += 1\n",
    "        state = next_state\n",
    "\n",
    "    states, actions, rewards = map(list, zip(*memory))\n",
    "\n",
    "    discounted_rewards = np.zeros((len(rewards)))\n",
    "    discount = 0\n",
    "    # Discounts rewards in reverse\n",
    "    for i in reversed(range(len(rewards))):\n",
    "\n",
    "        # Discount fowards from the future for previous states\n",
    "        discount = rewards[i] + discount*GAMMA \n",
    "        discounted_rewards[i] = discount\n",
    "\n",
    "    return to_torch(states).mean(dim=3).unsqueeze(dim=1), to_torch(actions), to_torch(discounted_rewards), timesteps, np.sum(rewards)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "CLIP_EPSILON = 0.2\n",
    "\n",
    "value_loss_fn = nn.SmoothL1Loss()\n",
    "def compute_losses(states, actions, rewards):\n",
    "    # Compute policy loss first\n",
    "    # Compute ratios \n",
    "    new_actions, values = agent(states)\n",
    "    ratios = new_actions / actions\n",
    "\n",
    "    advantages = rewards.unsqueeze(dim=1) - values\n",
    "\n",
    "    policy_loss = torch.min(ratios*advantages, torch.clip(ratios, 1 - CLIP_EPSILON, 1 + CLIP_EPSILON)*advantages)\n",
    "    policy_loss = -torch.mean(policy_loss)\n",
    "\n",
    "    # Compute value loss\n",
    "    value_loss = value_loss_fn(rewards, values)\n",
    "    \n",
    "    return policy_loss, value_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "def train():\n",
    "    n_time_steps = 100000\n",
    "    n_updates_per_episode = 5\n",
    "    \n",
    "    value_factor = 0.3\n",
    "\n",
    "    current_time_step = 0\n",
    "\n",
    "    agent_optimizer = optim.Adam(agent.parameters(), lr=0.0005)\n",
    "    scores = []\n",
    "    while current_time_step < n_time_steps:\n",
    "        with torch.no_grad():\n",
    "            states, actions, rewards, timesteps, episode_score = rollout(0.97**len(scores))\n",
    "        scores.append(episode_score)\n",
    "        print(f\"Current score: {scores[-1]}\")\n",
    "        print(f\"Total timesteps: {current_time_step}\")\n",
    "        current_time_step += timesteps\n",
    "\n",
    "        for _ in range(n_updates_per_episode):\n",
    "\n",
    "            agent_optimizer.zero_grad()\n",
    "            policy_loss, value_loss = compute_losses(states, actions, rewards)\n",
    "\n",
    "            loss = policy_loss + value_factor*value_loss\n",
    "            loss.backward()\n",
    "\n",
    "            agent_optimizer.step()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Track generation: 1189..1490 -> 301-tiles track\n",
      "Current score: -73.33333333333337\n",
      "Total timesteps: 0\n",
      "Track generation: 1135..1423 -> 288-tiles track\n",
      "C:\\Users\\franc\\AppData\\Roaming\\Python\\Python38\\site-packages\\torch\\nn\\modules\\loss.py:907: UserWarning: Using a target size (torch.Size([1000, 1])) that is different to the input size (torch.Size([1000])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.smooth_l1_loss(input, target, reduction=self.reduction, beta=self.beta)\n",
      "Current score: -61.672473867596416\n",
      "Total timesteps: 1000\n",
      "Track generation: 1093..1370 -> 277-tiles track\n",
      "Current score: -71.01449275362373\n",
      "Total timesteps: 2000\n",
      "Track generation: 1205..1510 -> 305-tiles track\n",
      "Current score: -90.13157894736757\n",
      "Total timesteps: 3000\n",
      "Track generation: 880..1111 -> 231-tiles track\n",
      "Current score: -69.56521739130471\n",
      "Total timesteps: 4000\n",
      "Track generation: 1074..1347 -> 273-tiles track\n",
      "Current score: -74.264705882353\n",
      "Total timesteps: 5000\n",
      "Track generation: 1271..1594 -> 323-tiles track\n",
      "Current score: -108.67701863354071\n",
      "Total timesteps: 6000\n",
      "Track generation: 1185..1485 -> 300-tiles track\n",
      "C:\\Users\\franc\\AppData\\Roaming\\Python\\Python38\\site-packages\\torch\\nn\\modules\\loss.py:907: UserWarning: Using a target size (torch.Size([771, 1])) that is different to the input size (torch.Size([771])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.smooth_l1_loss(input, target, reduction=self.reduction, beta=self.beta)\n",
      "Current score: -49.8327759197328\n",
      "Total timesteps: 6771\n",
      "Track generation: 1154..1447 -> 293-tiles track\n",
      "Current score: -143.17945205479504\n",
      "Total timesteps: 7771\n",
      "Track generation: 1032..1301 -> 269-tiles track\n",
      "C:\\Users\\franc\\AppData\\Roaming\\Python\\Python38\\site-packages\\torch\\nn\\modules\\loss.py:907: UserWarning: Using a target size (torch.Size([878, 1])) that is different to the input size (torch.Size([878])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.smooth_l1_loss(input, target, reduction=self.reduction, beta=self.beta)\n",
      "Current score: -62.686567164179806\n",
      "Total timesteps: 8649\n",
      "Track generation: 1052..1319 -> 267-tiles track\n",
      "Current score: -62.406015037594756\n",
      "Total timesteps: 9649\n",
      "Track generation: 1165..1460 -> 295-tiles track\n",
      "Current score: -35.37414965986474\n",
      "Total timesteps: 10649\n",
      "Track generation: 1034..1301 -> 267-tiles track\n",
      "Current score: -77.44360902255602\n",
      "Total timesteps: 11649\n",
      "Track generation: 1207..1512 -> 305-tiles track\n",
      "Current score: -50.65789473684308\n",
      "Total timesteps: 12649\n",
      "Track generation: 1152..1444 -> 292-tiles track\n",
      "Current score: -62.19931271477722\n",
      "Total timesteps: 13649\n",
      "Track generation: 1356..1710 -> 354-tiles track\n",
      "Current score: -71.67138810198355\n",
      "Total timesteps: 14649\n",
      "Track generation: 1149..1440 -> 291-tiles track\n",
      "Current score: -62.06896551724192\n",
      "Total timesteps: 15649\n",
      "Track generation: 1146..1436 -> 290-tiles track\n",
      "Current score: -89.61937716262875\n",
      "Total timesteps: 16649\n",
      "Track generation: 1163..1458 -> 295-tiles track\n",
      "Current score: -38.775510204082096\n",
      "Total timesteps: 17649\n",
      "Track generation: 1211..1518 -> 307-tiles track\n",
      "Current score: -67.32026143790924\n",
      "Total timesteps: 18649\n",
      "Track generation: 1068..1339 -> 271-tiles track\n",
      "Current score: -70.37037037037058\n",
      "Total timesteps: 19649\n",
      "Track generation: 1129..1416 -> 287-tiles track\n",
      "Current score: -51.048951048951764\n",
      "Total timesteps: 20649\n",
      "Track generation: 1184..1484 -> 300-tiles track\n",
      "Current score: -89.96655518394545\n",
      "Total timesteps: 21649\n",
      "Track generation: 1168..1464 -> 296-tiles track\n",
      "Current score: -132.38135593220355\n",
      "Total timesteps: 22649\n",
      "Track generation: 1036..1299 -> 263-tiles track\n",
      "C:\\Users\\franc\\AppData\\Roaming\\Python\\Python38\\site-packages\\torch\\nn\\modules\\loss.py:907: UserWarning: Using a target size (torch.Size([596, 1])) that is different to the input size (torch.Size([596])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.smooth_l1_loss(input, target, reduction=self.reduction, beta=self.beta)\n",
      "Current score: -77.09923664122127\n",
      "Total timesteps: 23245\n",
      "Track generation: 1236..1559 -> 323-tiles track\n",
      "Current score: 2.4844720496888115\n",
      "Total timesteps: 24245\n",
      "Track generation: 1232..1544 -> 312-tiles track\n",
      "Current score: -80.70739549839126\n",
      "Total timesteps: 25245\n",
      "Track generation: 1040..1310 -> 270-tiles track\n",
      "Current score: -40.52044609665489\n",
      "Total timesteps: 26245\n",
      "Track generation: 1308..1639 -> 331-tiles track\n",
      "Current score: -15.151515151515472\n",
      "Total timesteps: 27245\n",
      "Track generation: 1303..1633 -> 330-tiles track\n",
      "Current score: 0.30395136778156484\n",
      "Total timesteps: 28245\n",
      "Track generation: 1151..1443 -> 292-tiles track\n",
      "Current score: -72.5085910652923\n",
      "Total timesteps: 29245\n",
      "Track generation: 1141..1429 -> 288-tiles track\n",
      "Current score: -86.0627177700342\n",
      "Total timesteps: 30245\n",
      "Track generation: 1224..1534 -> 310-tiles track\n",
      "Current score: -28.80258899676455\n",
      "Total timesteps: 31245\n",
      "Track generation: 959..1203 -> 244-tiles track\n",
      "Current score: -34.1563786008238\n",
      "Total timesteps: 32245\n",
      "Track generation: 1088..1364 -> 276-tiles track\n",
      "Current score: 30.90909090909333\n",
      "Total timesteps: 33245\n",
      "Track generation: 992..1244 -> 252-tiles track\n",
      "Current score: 19.521912350598207\n",
      "Total timesteps: 34245\n",
      "Track generation: 1141..1430 -> 289-tiles track\n",
      "Current score: -54.8611111111117\n",
      "Total timesteps: 35245\n",
      "Track generation: 939..1183 -> 244-tiles track\n",
      "Current score: -50.617283950617605\n",
      "Total timesteps: 36245\n",
      "Track generation: 1050..1321 -> 271-tiles track\n",
      "Current score: 48.14814814814738\n",
      "Total timesteps: 37245\n",
      "Track generation: 1069..1347 -> 278-tiles track\n",
      "Current score: -35.018050541516416\n",
      "Total timesteps: 38245\n",
      "Track generation: 1221..1530 -> 309-tiles track\n",
      "Current score: -145.5857142857147\n",
      "Total timesteps: 39245\n",
      "Track generation: 1252..1569 -> 317-tiles track\n",
      "C:\\Users\\franc\\AppData\\Roaming\\Python\\Python38\\site-packages\\torch\\nn\\modules\\loss.py:907: UserWarning: Using a target size (torch.Size([814, 1])) that is different to the input size (torch.Size([814])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.smooth_l1_loss(input, target, reduction=self.reduction, beta=self.beta)\n",
      "Current score: -24.050632911392864\n",
      "Total timesteps: 40059\n",
      "Track generation: 1218..1527 -> 309-tiles track\n",
      "Current score: -80.51948051947966\n",
      "Total timesteps: 41059\n",
      "Track generation: 1132..1419 -> 287-tiles track\n",
      "Current score: -75.52447552447543\n",
      "Total timesteps: 42059\n",
      "Track generation: 1076..1349 -> 273-tiles track\n",
      "Current score: -92.6470588235284\n",
      "Total timesteps: 43059\n",
      "Track generation: 1112..1394 -> 282-tiles track\n",
      "Current score: -112.81281138790037\n",
      "Total timesteps: 44059\n",
      "Track generation: 1020..1279 -> 259-tiles track\n",
      "C:\\Users\\franc\\AppData\\Roaming\\Python\\Python38\\site-packages\\torch\\nn\\modules\\loss.py:907: UserWarning: Using a target size (torch.Size([485, 1])) that is different to the input size (torch.Size([485])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.smooth_l1_loss(input, target, reduction=self.reduction, beta=self.beta)\n",
      "Current score: -88.37209302325505\n",
      "Total timesteps: 44544\n",
      "Track generation: 1240..1554 -> 314-tiles track\n",
      "Current score: -68.05111821086298\n",
      "Total timesteps: 45544\n",
      "Track generation: 1076..1349 -> 273-tiles track\n",
      "Current score: -77.94117647058803\n",
      "Total timesteps: 46544\n",
      "Track generation: 1131..1424 -> 293-tiles track\n",
      "Current score: -113.70821917808242\n",
      "Total timesteps: 47544\n",
      "Track generation: 1188..1489 -> 301-tiles track\n",
      "C:\\Users\\franc\\AppData\\Roaming\\Python\\Python38\\site-packages\\torch\\nn\\modules\\loss.py:907: UserWarning: Using a target size (torch.Size([960, 1])) that is different to the input size (torch.Size([960])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.smooth_l1_loss(input, target, reduction=self.reduction, beta=self.beta)\n",
      "Current score: -86.66666666666605\n",
      "Total timesteps: 48504\n",
      "Track generation: 1211..1518 -> 307-tiles track\n",
      "Current score: -70.58823529411677\n",
      "Total timesteps: 49504\n",
      "Track generation: 1210..1520 -> 310-tiles track\n",
      "retry to generate track (normal if there are not manyinstances of this message)\n",
      "Track generation: 1059..1337 -> 278-tiles track\n",
      "Current score: -74.72924187725627\n",
      "Total timesteps: 50504\n",
      "Track generation: 1248..1564 -> 316-tiles track\n",
      "Current score: -58.73015873015923\n",
      "Total timesteps: 51504\n",
      "Track generation: 1195..1498 -> 303-tiles track\n",
      "Current score: -63.576158940398415\n",
      "Total timesteps: 52504\n",
      "Track generation: 1396..1748 -> 352-tiles track\n",
      "Current score: -91.45299145299052\n",
      "Total timesteps: 53504\n",
      "Track generation: 1241..1559 -> 318-tiles track\n",
      "retry to generate track (normal if there are not manyinstances of this message)\n",
      "Track generation: 1084..1363 -> 279-tiles track\n",
      "Current score: -85.6115107913663\n",
      "Total timesteps: 54504\n",
      "Track generation: 1411..1768 -> 357-tiles track\n",
      "Current score: -69.10112359550592\n",
      "Total timesteps: 55504\n",
      "Track generation: 1063..1333 -> 270-tiles track\n",
      "Current score: -25.650557620818546\n",
      "Total timesteps: 56504\n",
      "Track generation: 1253..1571 -> 318-tiles track\n",
      "Current score: -93.76309148265017\n",
      "Total timesteps: 57504\n",
      "Track generation: 1289..1615 -> 326-tiles track\n",
      "C:\\Users\\franc\\AppData\\Roaming\\Python\\Python38\\site-packages\\torch\\nn\\modules\\loss.py:907: UserWarning: Using a target size (torch.Size([538, 1])) that is different to the input size (torch.Size([538])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.smooth_l1_loss(input, target, reduction=self.reduction, beta=self.beta)\n",
      "Current score: -102.22307692307703\n",
      "Total timesteps: 58042\n",
      "Track generation: 1081..1356 -> 275-tiles track\n",
      "C:\\Users\\franc\\AppData\\Roaming\\Python\\Python38\\site-packages\\torch\\nn\\modules\\loss.py:907: UserWarning: Using a target size (torch.Size([454, 1])) that is different to the input size (torch.Size([454])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.smooth_l1_loss(input, target, reduction=self.reduction, beta=self.beta)\n",
      "Current score: -8.759124087591413\n",
      "Total timesteps: 58496\n",
      "Track generation: 1188..1496 -> 308-tiles track\n",
      "Current score: -38.110749185668\n",
      "Total timesteps: 59496\n",
      "Track generation: 1132..1419 -> 287-tiles track\n",
      "Current score: -30.06993006993038\n",
      "Total timesteps: 60496\n",
      "Track generation: 1038..1307 -> 269-tiles track\n",
      "Current score: -40.29850746268697\n",
      "Total timesteps: 61496\n",
      "Track generation: 1223..1533 -> 310-tiles track\n",
      "Current score: -83.81877022653615\n",
      "Total timesteps: 62496\n",
      "Track generation: 1026..1289 -> 263-tiles track\n",
      "retry to generate track (normal if there are not manyinstances of this message)\n",
      "Track generation: 1029..1290 -> 261-tiles track\n",
      "Current score: -141.19230769230808\n",
      "Total timesteps: 63496\n",
      "Track generation: 1163..1458 -> 295-tiles track\n",
      "C:\\Users\\franc\\AppData\\Roaming\\Python\\Python38\\site-packages\\torch\\nn\\modules\\loss.py:907: UserWarning: Using a target size (torch.Size([836, 1])) that is different to the input size (torch.Size([836])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.smooth_l1_loss(input, target, reduction=self.reduction, beta=self.beta)\n",
      "Current score: -89.79591836734616\n",
      "Total timesteps: 64332\n",
      "Track generation: 1255..1573 -> 318-tiles track\n",
      "Current score: -74.7634069400622\n",
      "Total timesteps: 65332\n",
      "Track generation: 1210..1516 -> 306-tiles track\n",
      "Current score: -70.49180327868874\n",
      "Total timesteps: 66332\n",
      "Track generation: 1034..1306 -> 272-tiles track\n",
      "Current score: -66.78966789667895\n",
      "Total timesteps: 67332\n",
      "Track generation: 1060..1338 -> 278-tiles track\n",
      "Current score: -86.94837545126393\n",
      "Total timesteps: 68332\n",
      "Track generation: 1123..1411 -> 288-tiles track\n",
      "retry to generate track (normal if there are not manyinstances of this message)\n",
      "Track generation: 1164..1459 -> 295-tiles track\n",
      "C:\\Users\\franc\\AppData\\Roaming\\Python\\Python38\\site-packages\\torch\\nn\\modules\\loss.py:907: UserWarning: Using a target size (torch.Size([412, 1])) that is different to the input size (torch.Size([412])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.smooth_l1_loss(input, target, reduction=self.reduction, beta=self.beta)\n",
      "Current score: -115.06734693877615\n",
      "Total timesteps: 68744\n",
      "Track generation: 1039..1303 -> 264-tiles track\n",
      "C:\\Users\\franc\\AppData\\Roaming\\Python\\Python38\\site-packages\\torch\\nn\\modules\\loss.py:907: UserWarning: Using a target size (torch.Size([968, 1])) that is different to the input size (torch.Size([968])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.smooth_l1_loss(input, target, reduction=self.reduction, beta=self.beta)\n",
      "Current score: -16.349809885931677\n",
      "Total timesteps: 69712\n",
      "Track generation: 1082..1362 -> 280-tiles track\n",
      "Current score: -102.49426523297578\n",
      "Total timesteps: 70712\n",
      "Track generation: 1182..1482 -> 300-tiles track\n",
      "C:\\Users\\franc\\AppData\\Roaming\\Python\\Python38\\site-packages\\torch\\nn\\modules\\loss.py:907: UserWarning: Using a target size (torch.Size([922, 1])) that is different to the input size (torch.Size([922])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.smooth_l1_loss(input, target, reduction=self.reduction, beta=self.beta)\n",
      "Current score: -63.221404682274645\n",
      "Total timesteps: 71634\n",
      "Track generation: 1037..1305 -> 268-tiles track\n",
      "C:\\Users\\franc\\AppData\\Roaming\\Python\\Python38\\site-packages\\torch\\nn\\modules\\loss.py:907: UserWarning: Using a target size (torch.Size([369, 1])) that is different to the input size (torch.Size([369])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.smooth_l1_loss(input, target, reduction=self.reduction, beta=self.beta)\n",
      "Current score: -2.368539325841681\n",
      "Total timesteps: 72003\n",
      "Track generation: 998..1255 -> 257-tiles track\n",
      "retry to generate track (normal if there are not manyinstances of this message)\n",
      "Track generation: 1276..1599 -> 323-tiles track\n",
      "C:\\Users\\franc\\AppData\\Roaming\\Python\\Python38\\site-packages\\torch\\nn\\modules\\loss.py:907: UserWarning: Using a target size (torch.Size([373, 1])) that is different to the input size (torch.Size([373])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.smooth_l1_loss(input, target, reduction=self.reduction, beta=self.beta)\n",
      "Current score: -75.18819875776431\n",
      "Total timesteps: 72376\n",
      "Track generation: 1163..1458 -> 295-tiles track\n",
      "C:\\Users\\franc\\AppData\\Roaming\\Python\\Python38\\site-packages\\torch\\nn\\modules\\loss.py:907: UserWarning: Using a target size (torch.Size([374, 1])) that is different to the input size (torch.Size([374])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.smooth_l1_loss(input, target, reduction=self.reduction, beta=self.beta)\n",
      "Current score: -21.76870748299382\n",
      "Total timesteps: 72750\n",
      "Track generation: 1051..1318 -> 267-tiles track\n",
      "Current score: -77.44360902255623\n",
      "Total timesteps: 73750\n",
      "Track generation: 1160..1454 -> 294-tiles track\n",
      "Current score: 56.99658703071672\n",
      "Total timesteps: 74750\n",
      "Track generation: 1200..1504 -> 304-tiles track\n",
      "Current score: -47.194719471947835\n",
      "Total timesteps: 75750\n",
      "Track generation: 1060..1336 -> 276-tiles track\n",
      "Current score: -45.454545454546086\n",
      "Total timesteps: 76750\n",
      "Track generation: 1251..1568 -> 317-tiles track\n",
      "Current score: -33.5443037974694\n",
      "Total timesteps: 77750\n",
      "Track generation: 1459..1828 -> 369-tiles track\n",
      "Current score: -45.65217391304411\n",
      "Total timesteps: 78750\n",
      "Track generation: 990..1249 -> 259-tiles track\n",
      "Current score: -61.240310077519936\n",
      "Total timesteps: 79750\n",
      "Track generation: 1304..1634 -> 330-tiles track\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-2da0ffaf5447>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-7-9c5f55ad065e>\u001b[0m in \u001b[0;36mtrain\u001b[1;34m()\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[1;32mwhile\u001b[0m \u001b[0mcurrent_time_step\u001b[0m \u001b[1;33m<\u001b[0m \u001b[0mn_time_steps\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m             \u001b[0mstates\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mactions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrewards\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimesteps\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepisode_score\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrollout\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0.97\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m         \u001b[0mscores\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepisode_score\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"Current score: {scores[-1]}\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-5-df0894c341d8>\u001b[0m in \u001b[0;36mrollout\u001b[1;34m(noise_factor)\u001b[0m\n\u001b[0;32m     39\u001b[0m         \u001b[0mdiscounted_rewards\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdiscount\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     40\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 41\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mto_torch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstates\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mto_torch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mactions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mto_torch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdiscounted_rewards\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimesteps\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrewards\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-5-df0894c341d8>\u001b[0m in \u001b[0;36mto_torch\u001b[1;34m(tensor)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mto_torch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mget_action\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maction_noise\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnoise_factor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mprobs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0magent\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}
{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python388jvsc74a57bd08420e9e93c695d97be91f5272eab9214f2b8a154faa67cd6133f765f4ca85a58",
   "display_name": "Python 3.8.8 64-bit"
  },
  "metadata": {
   "interpreter": {
    "hash": "8420e9e93c695d97be91f5272eab9214f2b8a154faa67cd6133f765f4ca85a58"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "from scipy.stats import multivariate_normal\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.distributions import MultivariateNormal\n",
    "import numpy as np\n",
    "from collections import deque\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "env = gym.make('CarRacing-v0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN_Network(nn.Module):\n",
    "    def __init__(self, output_size):\n",
    "        super(CNN_Network, self).__init__()\n",
    "\n",
    "        self.conv2d_0 = nn.Conv2d(1, 16, kernel_size=4, stride=2)\n",
    "        self.relu_0 = nn.LeakyReLU()\n",
    "\n",
    "        self.conv2d_1 = nn.Conv2d(16, 32, kernel_size=3, stride=2)\n",
    "        self.relu_1 = nn.LeakyReLU()\n",
    "\n",
    "        # self.conv2d_2 = nn.Conv2d(16, 32, kernel_size=3, stride=2)\n",
    "        # self.relu_2 = nn.LeakyReLU()\n",
    "\n",
    "        self.conv2d_3 = nn.Conv2d(32, 64, kernel_size=3, stride=2)\n",
    "        self.relu_3 = nn.LeakyReLU()\n",
    "\n",
    "        self.conv2d_4 = nn.Conv2d(64, 128, kernel_size=3, stride=2, padding=1)\n",
    "        self.relu_4 = nn.LeakyReLU()\n",
    "\n",
    "        # self.conv2d_5 = nn.Conv2d(128, 256, kernel_size=3, stride=2)\n",
    "        # self.relu_5 = nn.LeakyReLU()\n",
    "\n",
    "        self.action_linear_1 = nn.Linear(4608, 256)\n",
    "        self.relu_action_1 = nn.LeakyReLU()\n",
    "        self.action_linear_2 = nn.Linear(256, output_size)\n",
    "        self.activation_action1 = nn.Tanh()\n",
    "        self.activation_action2 = nn.ReLU()\n",
    "\n",
    "        self.value_linear_1 = nn.Linear(4608, 256)\n",
    "        self.relu_value_1 = nn.LeakyReLU()\n",
    "        self.value_linear_2 = nn.Linear(256, 1)\n",
    "\n",
    "        for layer in [self.conv2d_0 , self.conv2d_1,self.conv2d_3, self.conv2d_4, self.action_linear_1, self.action_linear_2, self.value_linear_1, self.value_linear_2]:\n",
    "            torch.nn.init.xavier_normal_(layer.weight)\n",
    "            torch.nn.init.zeros_(layer.bias)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.relu_0(self.conv2d_0(x))\n",
    "        x = self.relu_1(self.conv2d_1(x))\n",
    "        # x = self.relu_2(self.conv2d_2(x))\n",
    "        x = self.relu_3(self.conv2d_3(x))\n",
    "        x = self.relu_4(self.conv2d_4(x))\n",
    "        # x = self.relu_5(self.conv2d_5(x))\n",
    "        x = x.view(x.shape[0], -1)\n",
    "\n",
    "        x_action = self.action_linear_1(x)\n",
    "        x_action = self.action_linear_2(x_action)\n",
    "        # x_action = self.activation_action1(x_action)\n",
    "\n",
    "        x_value = self.relu_value_1(self.value_linear_1(x))\n",
    "        x_value = self.value_linear_2(x_value)\n",
    "        return x_action, x_value\n",
    "\n",
    "agent = CNN_Network(3).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "CNN_Network(\n  (conv2d_0): Conv2d(1, 16, kernel_size=(4, 4), stride=(2, 2))\n  (relu_0): LeakyReLU(negative_slope=0.01)\n  (conv2d_1): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2))\n  (relu_1): LeakyReLU(negative_slope=0.01)\n  (conv2d_3): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2))\n  (relu_3): LeakyReLU(negative_slope=0.01)\n  (conv2d_4): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n  (relu_4): LeakyReLU(negative_slope=0.01)\n  (action_linear_1): Linear(in_features=4608, out_features=256, bias=True)\n  (relu_action_1): LeakyReLU(negative_slope=0.01)\n  (action_linear_2): Linear(in_features=256, out_features=3, bias=True)\n  (activation_action1): Tanh()\n  (activation_action2): ReLU()\n  (value_linear_1): Linear(in_features=4608, out_features=256, bias=True)\n  (relu_value_1): LeakyReLU(negative_slope=0.01)\n  (value_linear_2): Linear(in_features=256, out_features=1, bias=True)\n)\n"
     ]
    }
   ],
   "source": [
    "print(agent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# class OrnsteinUhlenbeckActionNoise():\n",
    "#     def __init__(self, mu, sigma=0.3, theta=.10, dt=1e-2, x0=None):\n",
    "#         self.theta = theta\n",
    "#         self.mu = mu\n",
    "#         self.sigma = sigma\n",
    "#         self.dt = dt\n",
    "#         self.x0 = x0\n",
    "#         self.reset()\n",
    "\n",
    "#     def __call__(self):\n",
    "#         x = self.x_prev + self.theta * (self.mu - self.x_prev) * self.dt + \\\n",
    "#                 self.sigma * self.dt**(1/2) * torch.normal(mean=0.0, std=1.0, size=self.mu.shape, device=device)\n",
    "#         self.x_prev = x\n",
    "#         return x\n",
    "\n",
    "#     def reset(self):\n",
    "#         self.x_prev = self.x0 if self.x0 is not None else torch.zeros_like(self.mu, device=device)\n",
    "\n",
    "#     def __repr__(self):\n",
    "#         return 'OrnsteinUhlenbeckActionNoise(mu={}, sigma={})'.format(self.mu, self.sigma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_torch(tensor):\n",
    "    return torch.tensor(tensor.copy(), dtype=torch.float32, device=device)\n",
    "\n",
    "cov_exploration_matrix = torch.tensor([0.25, 0.1, 0.02], device=device)\n",
    "cov_mat = torch.diag(cov_exploration_matrix)\n",
    "def get_action(state):\n",
    "    actions, values = agent(state)\n",
    "    actions = actions[0]\n",
    "    distribution = MultivariateNormal(actions, cov_mat)\n",
    "    actions_with_exploration = distribution.sample()\n",
    "    log_actions = distribution.log_prob(actions_with_exploration)\n",
    "\n",
    "    return actions_with_exploration.cpu().numpy(), log_actions.cpu().numpy()\n",
    "\n",
    "GAMMA = 0.99\n",
    "def rollout(render, exploration_scale):\n",
    "    base_exploration = [0.25, 0.1, 0.02]\n",
    "    cov_exploration_matrix = torch.tensor(base_exploration, device=device) * min(exploration_scale, 0.5)\n",
    "\n",
    "    state = env.reset() / 255.\n",
    "    memory = []\n",
    "    timesteps = 0\n",
    "    done = False\n",
    "    streak = 0\n",
    "    while not done:\n",
    "        \n",
    "        action, log_action = get_action(to_torch(state).mean(dim=2).reshape(1, 1, state.shape[0], state.shape[1]))\n",
    "\n",
    "        for i in range(1):\n",
    "            if render or timesteps%100==0:\n",
    "                env.render()\n",
    "            \n",
    "\n",
    "            next_state, reward, done, _ = env.step(action)\n",
    "\n",
    "            \n",
    "\n",
    "            if np.mean(next_state[:, :, 1]) > 185.0:\n",
    "                reward -= 0.05\n",
    "\n",
    "            if reward < 0:\n",
    "                streak +=1\n",
    "                if streak > 300:\n",
    "                    done = True\n",
    "            else:\n",
    "                streak = 0\n",
    "\n",
    "            # reward += 0.1*np.clip(action[1], 0, 1)\n",
    "\n",
    "            next_state = next_state / 255.\n",
    "            memory.append([state, action, reward, log_action])\n",
    "            timesteps += 1\n",
    "            state = next_state\n",
    "\n",
    "            \n",
    "            if done: \n",
    "                break\n",
    "\n",
    "    states, actions, rewards, log_actions = map(np.array, zip(*memory))\n",
    "\n",
    "    discounted_rewards = np.zeros((len(rewards)))\n",
    "    discount = 0\n",
    "    # Discounts rewards in reverse\n",
    "    for i in reversed(range(len(rewards))):\n",
    "\n",
    "        # Discount fowards from the future for previous states\n",
    "        discount = rewards[i] + discount*GAMMA \n",
    "        discounted_rewards[i] = discount\n",
    "\n",
    "    return to_torch(states).mean(dim=3).unsqueeze(dim=1), to_torch(actions), to_torch(discounted_rewards).reshape(-1,1), to_torch(log_actions), timesteps, np.sum(rewards)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "CLIP_EPSILON = 0.2\n",
    "value_loss_fn = nn.SmoothL1Loss()\n",
    "\n",
    "def get_log_probs_and_value(states, old_actions):\n",
    "    actions, values = agent(states)\n",
    "    distribution = MultivariateNormal(actions, cov_mat)\n",
    "    log_actions = distribution.log_prob(old_actions)\n",
    "\n",
    "    return actions, log_actions, values, distribution.entropy()\n",
    "\n",
    "def compute_advantages(states, rewards):\n",
    "    _, values = agent(states)\n",
    "\n",
    "    advantages = rewards - values.detach()\n",
    "    advantages = (advantages - advantages.mean()) / \\\n",
    "                (advantages.std() + 1e-8) \n",
    "\n",
    "    return advantages\n",
    "\n",
    "def compute_losses(states, actions, rewards, log_actions, advantages):\n",
    "    # Compute policy loss first\n",
    "    # Compute ratios \n",
    "    new_actions, log_new_actions, values, entropy = get_log_probs_and_value(states, actions)\n",
    "    ratios = torch.exp(log_new_actions - log_actions) \n",
    "\n",
    "    policy_loss = torch.min(ratios*advantages, torch.clip(ratios, 1 - CLIP_EPSILON, 1 + CLIP_EPSILON)*advantages)\n",
    "    policy_loss = -torch.mean(policy_loss)\n",
    "\n",
    "    # Compute value loss\n",
    "    value_loss = value_loss_fn(rewards, values)\n",
    "\n",
    "    # Compute entropy loss\n",
    "    entropy_loss = -torch.mean(entropy)\n",
    "    \n",
    "    return policy_loss, value_loss, entropy_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODOS\n",
    "# 1. new_actions / actions - > en log_probs (log_new_actions - log_actions)\n",
    "# 2. Trouver des meilleurs manières pour explorer\n",
    "# 3. tweak value_factor, GAMMA, exploration_factor, lr \n",
    "# 4. Tweak le modèle pytorch, activations\n",
    "\n",
    "\n",
    "def train():\n",
    "    n_time_steps = 1000000\n",
    "    n_updates_per_episode = 5\n",
    "    \n",
    "    value_factor = 0.3\n",
    "    entropy_factor = 0.01\n",
    "\n",
    "    current_time_step = 0\n",
    "    exploration_factor = 0.995\n",
    "\n",
    "    agent_optimizer = optim.Adam(agent.parameters(), lr=0.0001)\n",
    "    scores = []\n",
    "    while current_time_step < n_time_steps:\n",
    "        # try:\n",
    "        with torch.no_grad():\n",
    "            agent.eval()\n",
    "            states, actions, rewards, log_actions, timesteps, episode_score = rollout(len(scores)%5==0, exploration_factor**len(scores))\n",
    "        # except:\n",
    "        #     continue\n",
    "        scores.append(episode_score)\n",
    "        print(f\"Current score: {scores[-1]}\")\n",
    "        print(f\"Total timesteps: {current_time_step}\")\n",
    "        current_time_step += timesteps\n",
    "        print(cov_exploration_matrix)\n",
    "        advantages = compute_advantages(states, rewards)\n",
    "\n",
    "        agent.train()\n",
    "        for _ in range(n_updates_per_episode):\n",
    "            agent_optimizer.zero_grad()\n",
    "            policy_loss, value_loss, entropy_loss = compute_losses(states, actions, rewards, log_actions, advantages)\n",
    "\n",
    "            loss = policy_loss + value_factor*value_loss #+ entropy_factor*entropy_loss\n",
    "            print(f'loss: {loss}')\n",
    "            loss.backward()\n",
    "\n",
    "            agent_optimizer.step()\n",
    "            agent_optimizer.zero_grad()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Track generation: 1386..1737 -> 351-tiles track\n",
      "Current score: 10.47142857142763\n",
      "Total timesteps: 0\n",
      "tensor([0.2500, 0.0800], device='cuda:0')\n",
      "loss: 2.1659629344940186\n",
      "loss: 2.161029815673828\n",
      "loss: 2.156430959701538\n",
      "loss: 2.152118682861328\n",
      "loss: 2.147897243499756\n",
      "Track generation: 1184..1484 -> 300-tiles track\n",
      "Current score: 1.9120401337790316\n",
      "Total timesteps: 744\n",
      "tensor([0.2500, 0.0800], device='cuda:0')\n",
      "loss: 1.9051549434661865\n",
      "loss: 1.9025700092315674\n",
      "loss: 1.899826169013977\n",
      "loss: 1.8968665599822998\n",
      "loss: 1.8937265872955322\n",
      "Track generation: 1179..1478 -> 299-tiles track\n",
      "Current score: 1.6741610738252817\n",
      "Total timesteps: 1542\n",
      "tensor([0.2500, 0.0800], device='cuda:0')\n",
      "loss: 1.893082857131958\n",
      "loss: 1.885331392288208\n",
      "loss: 1.8766847848892212\n",
      "loss: 1.8670272827148438\n",
      "loss: 1.8562500476837158\n",
      "Track generation: 1168..1464 -> 296-tiles track\n",
      "Current score: 3.297457627118291\n",
      "Total timesteps: 1960\n",
      "tensor([0.2500, 0.0800], device='cuda:0')\n",
      "loss: 1.8023192882537842\n",
      "loss: 1.7881478071212769\n",
      "loss: 1.7724318504333496\n",
      "loss: 1.7552518844604492\n",
      "loss: 1.7364401817321777\n",
      "Track generation: 1128..1423 -> 295-tiles track\n",
      "Current score: 26.901700680271826\n",
      "Total timesteps: 2432\n",
      "tensor([0.2500, 0.0800], device='cuda:0')\n",
      "loss: 1.3643157482147217\n",
      "loss: 1.373169183731079\n",
      "loss: 1.380218744277954\n",
      "loss: 1.384973168373108\n",
      "loss: 1.3872731924057007\n",
      "Track generation: 1187..1487 -> 300-tiles track\n",
      "Current score: -33.46588628762562\n",
      "Total timesteps: 3432\n",
      "tensor([0.2500, 0.0800], device='cuda:0')\n",
      "loss: 1.1130722761154175\n",
      "loss: 1.107964038848877\n",
      "loss: 1.0989229679107666\n",
      "loss: 1.0866209268569946\n",
      "loss: 1.0715264081954956\n",
      "Track generation: 1108..1389 -> 281-tiles track\n",
      "Current score: 34.11428571428577\n",
      "Total timesteps: 4432\n",
      "tensor([0.2500, 0.0800], device='cuda:0')\n",
      "loss: 2.6384692192077637\n",
      "loss: 2.6345436573028564\n",
      "loss: 2.6310625076293945\n",
      "loss: 2.628066062927246\n",
      "loss: 2.6256051063537598\n",
      "Track generation: 1204..1509 -> 305-tiles track\n",
      "Current score: 92.77894736842299\n",
      "Total timesteps: 5432\n",
      "tensor([0.2500, 0.0800], device='cuda:0')\n",
      "loss: 3.2133824825286865\n",
      "loss: 3.292752504348755\n",
      "loss: 3.2159712314605713\n",
      "loss: 3.2923474311828613\n",
      "loss: 3.2472004890441895\n",
      "Track generation: 1164..1459 -> 295-tiles track\n",
      "Current score: 31.503061224489734\n",
      "Total timesteps: 6432\n",
      "tensor([0.2500, 0.0800], device='cuda:0')\n",
      "loss: 2.0200443267822266\n",
      "loss: 2.0566203594207764\n",
      "loss: 2.073014497756958\n",
      "loss: 2.0475211143493652\n",
      "loss: 2.039167642593384\n",
      "Track generation: 1045..1310 -> 265-tiles track\n",
      "Current score: -20.25606060606053\n",
      "Total timesteps: 7432\n",
      "tensor([0.2500, 0.0800], device='cuda:0')\n",
      "loss: 1.233582615852356\n",
      "loss: 1.243782877922058\n",
      "loss: 1.2529714107513428\n",
      "loss: 1.2355544567108154\n",
      "loss: 1.2260702848434448\n",
      "Track generation: 1124..1409 -> 285-tiles track\n",
      "Current score: -17.67323943661962\n",
      "Total timesteps: 8263\n",
      "tensor([0.2500, 0.0800], device='cuda:0')\n",
      "loss: 1.329013466835022\n",
      "loss: 1.3123573064804077\n",
      "loss: 1.2927078008651733\n",
      "loss: 1.2515685558319092\n",
      "loss: 1.2111411094665527\n",
      "Track generation: 1127..1413 -> 286-tiles track\n",
      "Current score: -6.863157894736741\n",
      "Total timesteps: 8628\n",
      "tensor([0.2500, 0.0800], device='cuda:0')\n",
      "loss: 1.0297521352767944\n",
      "loss: 1.0334619283676147\n",
      "loss: 1.0420218706130981\n",
      "loss: 1.039873480796814\n",
      "loss: 1.0452947616577148\n",
      "Track generation: 1165..1468 -> 303-tiles track\n",
      "Current score: -33.36357615894081\n",
      "Total timesteps: 9628\n",
      "tensor([0.2500, 0.0800], device='cuda:0')\n",
      "loss: 0.8946160078048706\n",
      "loss: 0.8785905838012695\n",
      "loss: 0.863688588142395\n",
      "loss: 0.8403220176696777\n",
      "loss: 0.8208950757980347\n",
      "Track generation: 1100..1384 -> 284-tiles track\n",
      "Current score: 22.37491166077617\n",
      "Total timesteps: 10628\n",
      "tensor([0.2500, 0.0800], device='cuda:0')\n",
      "loss: 1.7312368154525757\n",
      "loss: 1.7564622163772583\n",
      "loss: 1.761301875114441\n",
      "loss: 1.744424819946289\n",
      "loss: 1.7162301540374756\n",
      "Track generation: 1051..1325 -> 274-tiles track\n",
      "Current score: -9.724908424908454\n",
      "Total timesteps: 11628\n",
      "tensor([0.2500, 0.0800], device='cuda:0')\n",
      "loss: 1.4281563758850098\n",
      "loss: 1.4295048713684082\n",
      "loss: 1.4327391386032104\n",
      "loss: 1.4338648319244385\n",
      "loss: 1.4360953569412231\n",
      "Track generation: 1112..1394 -> 282-tiles track\n",
      "Current score: -27.410498220640676\n",
      "Total timesteps: 12628\n",
      "tensor([0.2500, 0.0800], device='cuda:0')\n",
      "loss: 0.8337860703468323\n",
      "loss: 0.837550699710846\n",
      "loss: 0.8395218849182129\n",
      "loss: 0.8400534391403198\n",
      "loss: 0.8382836580276489\n",
      "Track generation: 1192..1494 -> 302-tiles track\n",
      "Current score: 15.02906976744123\n",
      "Total timesteps: 13456\n",
      "tensor([0.2500, 0.0800], device='cuda:0')\n",
      "loss: 1.4652498960494995\n",
      "loss: 1.4647910594940186\n",
      "loss: 1.4594547748565674\n",
      "loss: 1.4502509832382202\n",
      "loss: 1.4382860660552979\n",
      "Track generation: 1219..1527 -> 308-tiles track\n",
      "Current score: -6.3521172638437395\n",
      "Total timesteps: 14456\n",
      "tensor([0.2500, 0.0800], device='cuda:0')\n",
      "loss: 1.3708508014678955\n",
      "loss: 1.369706630706787\n",
      "loss: 1.369016408920288\n",
      "loss: 1.3686822652816772\n",
      "loss: 1.368612289428711\n",
      "Track generation: 1328..1664 -> 336-tiles track\n",
      "Current score: -16.569402985074525\n",
      "Total timesteps: 15366\n",
      "tensor([0.2500, 0.0800], device='cuda:0')\n",
      "loss: 1.1755748987197876\n",
      "loss: 1.1793320178985596\n",
      "loss: 1.1763628721237183\n",
      "loss: 1.1679413318634033\n",
      "loss: 1.1545838117599487\n",
      "Track generation: 1153..1448 -> 295-tiles track\n",
      "retry to generate track (normal if there are not manyinstances of this message)\n",
      "Track generation: 1105..1389 -> 284-tiles track\n",
      "Current score: -37.162897526501894\n",
      "Total timesteps: 15746\n",
      "tensor([0.2500, 0.0800], device='cuda:0')\n",
      "loss: 0.6982710957527161\n",
      "loss: 0.6849309206008911\n",
      "loss: 0.6713740825653076\n",
      "loss: 0.6582480669021606\n",
      "loss: 0.6461891531944275\n",
      "Track generation: 1168..1464 -> 296-tiles track\n",
      "Current score: -15.071186440677875\n",
      "Total timesteps: 16672\n",
      "tensor([0.2500, 0.0800], device='cuda:0')\n",
      "loss: 0.9445797801017761\n",
      "loss: 0.9172539114952087\n",
      "loss: 0.8879918456077576\n",
      "loss: 0.857760488986969\n",
      "loss: 0.8274062871932983\n",
      "Track generation: 1323..1658 -> 335-tiles track\n",
      "Current score: -32.40778443113779\n",
      "Total timesteps: 17047\n",
      "tensor([0.2500, 0.0800], device='cuda:0')\n",
      "loss: 0.6338716149330139\n",
      "loss: 0.6473996639251709\n",
      "loss: 0.6621420979499817\n",
      "loss: 0.6753339767456055\n",
      "loss: 0.6847021579742432\n",
      "Track generation: 1141..1432 -> 291-tiles track\n",
      "retry to generate track (normal if there are not manyinstances of this message)\n",
      "Track generation: 1091..1368 -> 277-tiles track\n",
      "Current score: -6.578985507246456\n",
      "Total timesteps: 17907\n",
      "tensor([0.2500, 0.0800], device='cuda:0')\n",
      "loss: 1.381658673286438\n",
      "loss: 1.3796523809432983\n",
      "loss: 1.3721522092819214\n",
      "loss: 1.3604353666305542\n",
      "loss: 1.3458327054977417\n",
      "Track generation: 1152..1444 -> 292-tiles track\n",
      "Current score: -20.58573883161504\n",
      "Total timesteps: 18535\n",
      "tensor([0.2500, 0.0800], device='cuda:0')\n",
      "loss: 0.7593618631362915\n",
      "loss: 0.7614020705223083\n",
      "loss: 0.7644085884094238\n",
      "loss: 0.7675582766532898\n",
      "loss: 0.7702640891075134\n",
      "Track generation: 1050..1319 -> 269-tiles track\n",
      "retry to generate track (normal if there are not manyinstances of this message)\n",
      "Track generation: 1171..1468 -> 297-tiles track\n",
      "Current score: -30.966216216216313\n",
      "Total timesteps: 19068\n",
      "tensor([0.2500, 0.0800], device='cuda:0')\n",
      "loss: 0.6043108105659485\n",
      "loss: 0.604348361492157\n",
      "loss: 0.6006795167922974\n",
      "loss: 0.5942301154136658\n",
      "loss: 0.5859655737876892\n",
      "Track generation: 1092..1369 -> 277-tiles track\n",
      "Current score: -8.364492753623217\n",
      "Total timesteps: 19700\n",
      "tensor([0.2500, 0.0800], device='cuda:0')\n",
      "loss: 0.8727268576622009\n",
      "loss: 0.862649142742157\n",
      "loss: 0.852783203125\n",
      "loss: 0.8438223004341125\n",
      "loss: 0.8363509178161621\n",
      "Track generation: 1177..1476 -> 299-tiles track\n",
      "retry to generate track (normal if there are not manyinstances of this message)\n",
      "Track generation: 1135..1423 -> 288-tiles track\n",
      "Current score: -23.325435540069655\n",
      "Total timesteps: 20072\n",
      "tensor([0.2500, 0.0800], device='cuda:0')\n",
      "loss: 0.581418514251709\n",
      "loss: 0.5803353786468506\n",
      "loss: 0.5817435383796692\n",
      "loss: 0.5846849083900452\n",
      "loss: 0.5880748629570007\n",
      "Track generation: 1052..1318 -> 266-tiles track\n",
      "Current score: 8.083962264151081\n",
      "Total timesteps: 20565\n",
      "tensor([0.2500, 0.0800], device='cuda:0')\n",
      "loss: 2.059185743331909\n",
      "loss: 2.0285537242889404\n",
      "loss: 1.9594346284866333\n",
      "loss: 1.866119146347046\n",
      "loss: 1.7607409954071045\n",
      "Track generation: 1074..1347 -> 273-tiles track\n",
      "Current score: -12.714705882352902\n",
      "Total timesteps: 21565\n",
      "tensor([0.2500, 0.0800], device='cuda:0')\n",
      "loss: 0.8504721522331238\n",
      "loss: 0.8880911469459534\n",
      "loss: 0.9173908233642578\n",
      "loss: 0.9389240145683289\n",
      "loss: 0.9533556699752808\n",
      "Track generation: 1216..1524 -> 308-tiles track\n",
      "Current score: -11.1034201954397\n",
      "Total timesteps: 21934\n",
      "tensor([0.2500, 0.0800], device='cuda:0')\n",
      "loss: 1.1667380332946777\n",
      "loss: 1.1650121212005615\n",
      "loss: 1.1634600162506104\n",
      "loss: 1.1621158123016357\n",
      "loss: 1.1609604358673096\n",
      "Track generation: 1272..1595 -> 323-tiles track\n",
      "Current score: -29.021428571428558\n",
      "Total timesteps: 22676\n",
      "tensor([0.2500, 0.0800], device='cuda:0')\n",
      "loss: 0.903590738773346\n",
      "loss: 0.9044674634933472\n",
      "loss: 0.9052538275718689\n",
      "loss: 0.9058063626289368\n",
      "loss: 0.9061180353164673\n",
      "Track generation: 1081..1364 -> 283-tiles track\n",
      "Current score: 16.471276595744243\n",
      "Total timesteps: 23659\n",
      "tensor([0.2500, 0.0800], device='cuda:0')\n",
      "loss: 1.4998958110809326\n",
      "loss: 1.4888545274734497\n",
      "loss: 1.470359444618225\n",
      "loss: 1.4464137554168701\n",
      "loss: 1.4194748401641846\n",
      "Track generation: 1141..1437 -> 296-tiles track\n",
      "Current score: -25.372881355932158\n",
      "Total timesteps: 24659\n",
      "tensor([0.2500, 0.0800], device='cuda:0')\n",
      "loss: 1.127506971359253\n",
      "loss: 1.1403687000274658\n",
      "loss: 1.149825096130371\n",
      "loss: 1.15581214427948\n",
      "loss: 1.1585673093795776\n",
      "Track generation: 1144..1434 -> 290-tiles track\n",
      "Current score: -20.696885813148633\n",
      "Total timesteps: 25466\n",
      "tensor([0.2500, 0.0800], device='cuda:0')\n",
      "loss: 1.0001534223556519\n",
      "loss: 0.9982123970985413\n",
      "loss: 0.9946835041046143\n",
      "loss: 0.9899712800979614\n",
      "loss: 0.9844652414321899\n",
      "Track generation: 1288..1614 -> 326-tiles track\n",
      "Current score: -14.569230769230646\n",
      "Total timesteps: 26157\n",
      "tensor([0.2500, 0.0800], device='cuda:0')\n",
      "loss: 1.0736724138259888\n",
      "loss: 1.0687952041625977\n",
      "loss: 1.0639660358428955\n",
      "loss: 1.0594940185546875\n",
      "loss: 1.0550612211227417\n",
      "Track generation: 1176..1481 -> 305-tiles track\n",
      "Current score: -31.521052631579494\n",
      "Total timesteps: 26781\n",
      "tensor([0.2500, 0.0800], device='cuda:0')\n",
      "loss: 0.856085479259491\n",
      "loss: 0.8495804667472839\n",
      "loss: 0.8432662487030029\n",
      "loss: 0.8373666405677795\n",
      "loss: 0.8320643901824951\n",
      "Track generation: 1247..1563 -> 316-tiles track\n",
      "Current score: -24.65873015873009\n",
      "Total timesteps: 27781\n",
      "tensor([0.2500, 0.0800], device='cuda:0')\n",
      "loss: 0.8533620238304138\n",
      "loss: 0.8543925285339355\n",
      "loss: 0.8556888699531555\n",
      "loss: 0.85707688331604\n",
      "loss: 0.8584124445915222\n",
      "Track generation: 1247..1566 -> 319-tiles track\n",
      "Current score: -7.512264150943379\n",
      "Total timesteps: 28718\n",
      "tensor([0.2500, 0.0800], device='cuda:0')\n",
      "loss: 1.5122557878494263\n",
      "loss: 1.5115081071853638\n",
      "loss: 1.5108191967010498\n",
      "loss: 1.510201096534729\n",
      "loss: 1.5096591711044312\n",
      "Track generation: 1032..1301 -> 269-tiles track\n",
      "Current score: -27.155223880597237\n",
      "Total timesteps: 29441\n",
      "tensor([0.2500, 0.0800], device='cuda:0')\n",
      "loss: 0.9734379053115845\n",
      "loss: 0.9610602259635925\n",
      "loss: 0.9436564445495605\n",
      "loss: 0.9221146702766418\n",
      "loss: 0.8973822593688965\n",
      "Track generation: 1136..1424 -> 288-tiles track\n",
      "Current score: 10.529616724738375\n",
      "Total timesteps: 30123\n",
      "tensor([0.2500, 0.0800], device='cuda:0')\n",
      "loss: 2.0321764945983887\n",
      "loss: 2.0522446632385254\n",
      "loss: 2.0645360946655273\n",
      "loss: 2.0681560039520264\n",
      "loss: 2.0635337829589844\n",
      "Track generation: 1139..1428 -> 289-tiles track\n",
      "Current score: -19.19444444444431\n",
      "Total timesteps: 31047\n",
      "tensor([0.2500, 0.0800], device='cuda:0')\n",
      "loss: 0.9285129308700562\n",
      "loss: 0.9214338064193726\n",
      "loss: 0.9142010807991028\n",
      "loss: 0.9073493480682373\n",
      "loss: 0.9012528657913208\n",
      "Track generation: 1211..1518 -> 307-tiles track\n",
      "Current score: -14.712418300653448\n",
      "Total timesteps: 31792\n",
      "tensor([0.2500, 0.0800], device='cuda:0')\n",
      "loss: 1.0625759363174438\n",
      "loss: 1.0532894134521484\n",
      "loss: 1.0447300672531128\n",
      "loss: 1.03718900680542\n",
      "loss: 1.0308053493499756\n",
      "Track generation: 1004..1259 -> 255-tiles track\n",
      "Current score: -12.62795275590545\n",
      "Total timesteps: 32457\n",
      "tensor([0.2500, 0.0800], device='cuda:0')\n",
      "loss: 0.8769140839576721\n",
      "loss: 0.8883518576622009\n",
      "loss: 0.8921489715576172\n",
      "loss: 0.8892539739608765\n",
      "loss: 0.8804212212562561\n",
      "Track generation: 944..1184 -> 240-tiles track\n",
      "Current score: -21.072594142259348\n",
      "Total timesteps: 32814\n",
      "tensor([0.2500, 0.0800], device='cuda:0')\n",
      "loss: 0.7697129845619202\n",
      "loss: 0.7676973938941956\n",
      "loss: 0.7661966681480408\n",
      "loss: 0.7651802897453308\n",
      "loss: 0.7646074891090393\n",
      "Track generation: 1060..1330 -> 270-tiles track\n",
      "retry to generate track (normal if there are not manyinstances of this message)\n",
      "Track generation: 1145..1434 -> 289-tiles track\n",
      "Current score: -21.422222222222167\n",
      "Total timesteps: 33607\n",
      "tensor([0.2500, 0.0800], device='cuda:0')\n",
      "loss: 0.6703402996063232\n",
      "loss: 0.6608725190162659\n",
      "loss: 0.6500427722930908\n",
      "loss: 0.6384608149528503\n",
      "loss: 0.6267899870872498\n",
      "Track generation: 1088..1372 -> 284-tiles track\n",
      "Current score: -29.81219081272085\n",
      "Total timesteps: 34084\n",
      "tensor([0.2500, 0.0800], device='cuda:0')\n",
      "loss: 0.8794079422950745\n",
      "loss: 0.886787474155426\n",
      "loss: 0.8928869366645813\n",
      "loss: 0.8968930244445801\n",
      "loss: 0.8983342051506042\n",
      "Track generation: 1220..1532 -> 312-tiles track\n",
      "retry to generate track (normal if there are not manyinstances of this message)\n",
      "Track generation: 1208..1514 -> 306-tiles track\n",
      "Current score: -23.477049180327825\n",
      "Total timesteps: 35044\n",
      "tensor([0.2500, 0.0800], device='cuda:0')\n",
      "loss: 0.6322533488273621\n",
      "loss: 0.6312537789344788\n",
      "loss: 0.6300796270370483\n",
      "loss: 0.6288482546806335\n",
      "loss: 0.6276583671569824\n",
      "Track generation: 1172..1469 -> 297-tiles track\n",
      "Current score: -11.822972972972915\n",
      "Total timesteps: 35696\n",
      "tensor([0.2500, 0.0800], device='cuda:0')\n",
      "loss: 0.8025004267692566\n",
      "loss: 0.8021427392959595\n",
      "loss: 0.7999719381332397\n",
      "loss: 0.7964463233947754\n",
      "loss: 0.7918277382850647\n",
      "Track generation: 1235..1548 -> 313-tiles track\n",
      "Current score: -46.667948717948974\n",
      "Total timesteps: 36083\n",
      "tensor([0.2500, 0.0800], device='cuda:0')\n",
      "loss: 0.78826504945755\n",
      "loss: 0.780932605266571\n",
      "loss: 0.7726897597312927\n",
      "loss: 0.7641964554786682\n",
      "loss: 0.7559637427330017\n",
      "Track generation: 1072..1344 -> 272-tiles track\n",
      "Current score: -18.0498154981549\n",
      "Total timesteps: 37045\n",
      "tensor([0.2500, 0.0800], device='cuda:0')\n",
      "loss: 0.5604364275932312\n",
      "loss: 0.548646867275238\n",
      "loss: 0.5380319952964783\n",
      "loss: 0.5293824672698975\n",
      "loss: 0.5233036279678345\n",
      "Track generation: 1208..1514 -> 306-tiles track\n",
      "Current score: -42.43360655737747\n",
      "Total timesteps: 37393\n",
      "tensor([0.2500, 0.0800], device='cuda:0')\n",
      "loss: 0.7230411767959595\n",
      "loss: 0.7334675788879395\n",
      "loss: 0.7210274338722229\n",
      "loss: 0.6883980631828308\n",
      "loss: 0.6441863775253296\n",
      "Track generation: 1300..1629 -> 329-tiles track\n",
      "Current score: -35.26707317073182\n",
      "Total timesteps: 38393\n",
      "tensor([0.2500, 0.0800], device='cuda:0')\n",
      "loss: 0.6161810159683228\n",
      "loss: 0.630567193031311\n",
      "loss: 0.6463682651519775\n",
      "loss: 0.6485965251922607\n",
      "loss: 0.6422805190086365\n",
      "Track generation: 1336..1674 -> 338-tiles track\n",
      "Current score: -29.13961424332347\n",
      "Total timesteps: 39139\n",
      "tensor([0.2500, 0.0800], device='cuda:0')\n",
      "loss: 0.8385893702507019\n",
      "loss: 0.8367950320243835\n",
      "loss: 0.8356661200523376\n",
      "loss: 0.8351027965545654\n",
      "loss: 0.8348401188850403\n",
      "Track generation: 1162..1457 -> 295-tiles track\n",
      "Current score: -33.12959183673478\n",
      "Total timesteps: 39865\n",
      "tensor([0.2500, 0.0800], device='cuda:0')\n",
      "loss: 0.6199431419372559\n",
      "loss: 0.6193795800209045\n",
      "loss: 0.6172686815261841\n",
      "loss: 0.614224374294281\n",
      "loss: 0.6110028624534607\n",
      "Track generation: 1132..1419 -> 287-tiles track\n",
      "Current score: -30.474475524475633\n",
      "Total timesteps: 40694\n",
      "tensor([0.2500, 0.0800], device='cuda:0')\n",
      "loss: 0.4937940835952759\n",
      "loss: 0.4961644113063812\n",
      "loss: 0.49197280406951904\n",
      "loss: 0.4827600419521332\n",
      "loss: 0.47060102224349976\n",
      "Track generation: 1225..1535 -> 310-tiles track\n",
      "Current score: -35.575080906149225\n",
      "Total timesteps: 41237\n",
      "tensor([0.2500, 0.0800], device='cuda:0')\n",
      "loss: 0.6317689418792725\n",
      "loss: 0.6419156789779663\n",
      "loss: 0.6402884721755981\n",
      "loss: 0.6287182569503784\n",
      "loss: 0.61061692237854\n",
      "Track generation: 994..1248 -> 254-tiles track\n",
      "Current score: -19.21660079051385\n",
      "Total timesteps: 42237\n",
      "tensor([0.2500, 0.0800], device='cuda:0')\n",
      "loss: 0.7459360361099243\n",
      "loss: 0.7365691661834717\n",
      "loss: 0.73044353723526\n",
      "loss: 0.7274405360221863\n",
      "loss: 0.7271777987480164\n",
      "Track generation: 1151..1443 -> 292-tiles track\n",
      "Current score: -7.353608247422706\n",
      "Total timesteps: 42931\n",
      "tensor([0.2500, 0.0800], device='cuda:0')\n",
      "loss: 1.3456904888153076\n",
      "loss: 1.3392232656478882\n",
      "loss: 1.3331928253173828\n",
      "loss: 1.3277344703674316\n",
      "loss: 1.3229976892471313\n",
      "Track generation: 1055..1332 -> 277-tiles track\n",
      "Current score: -9.420289855072415\n",
      "Total timesteps: 43507\n",
      "tensor([0.2500, 0.0800], device='cuda:0')\n",
      "loss: 1.1378298997879028\n",
      "loss: 1.1323896646499634\n",
      "loss: 1.1282042264938354\n",
      "loss: 1.1252543926239014\n",
      "loss: 1.1234328746795654\n",
      "Track generation: 1019..1278 -> 259-tiles track\n",
      "Current score: -8.882558139534957\n",
      "Total timesteps: 44507\n",
      "tensor([0.2500, 0.0800], device='cuda:0')\n",
      "loss: 1.0374633073806763\n",
      "loss: 1.0308539867401123\n",
      "loss: 1.0248771905899048\n",
      "loss: 1.019800066947937\n",
      "loss: 1.0159186124801636\n",
      "Track generation: 1115..1401 -> 286-tiles track\n",
      "retry to generate track (normal if there are not manyinstances of this message)\n",
      "Track generation: 1159..1453 -> 294-tiles track\n",
      "Current score: -19.935153583617705\n",
      "Total timesteps: 45277\n",
      "tensor([0.2500, 0.0800], device='cuda:0')\n",
      "loss: 1.2073458433151245\n",
      "loss: 1.1908516883850098\n",
      "loss: 1.1497169733047485\n",
      "loss: 1.0986857414245605\n",
      "loss: 1.0447916984558105\n",
      "Track generation: 1205..1510 -> 305-tiles track\n",
      "Current score: -15.823684210526217\n",
      "Total timesteps: 45635\n",
      "tensor([0.2500, 0.0800], device='cuda:0')\n",
      "loss: 1.0200637578964233\n",
      "loss: 0.9768720269203186\n",
      "loss: 0.933289110660553\n",
      "loss: 0.8903544545173645\n",
      "loss: 0.8483691215515137\n",
      "Track generation: 1036..1299 -> 263-tiles track\n",
      "Current score: -17.86603053435107\n",
      "Total timesteps: 46010\n",
      "tensor([0.2500, 0.0800], device='cuda:0')\n",
      "loss: 0.7161272764205933\n",
      "loss: 0.666114866733551\n",
      "loss: 0.6198622584342957\n",
      "loss: 0.5804250836372375\n",
      "loss: 0.5507099628448486\n",
      "Track generation: 1117..1400 -> 283-tiles track\n",
      "Current score: -17.00460992907787\n",
      "Total timesteps: 46370\n",
      "tensor([0.2500, 0.0800], device='cuda:0')\n",
      "loss: 1.1735440492630005\n",
      "loss: 1.218611478805542\n",
      "loss: 1.248447299003601\n",
      "loss: 1.260539174079895\n",
      "loss: 1.2549225091934204\n",
      "Track generation: 1027..1288 -> 261-tiles track\n",
      "Current score: -13.738461538461328\n",
      "Total timesteps: 47023\n",
      "tensor([0.2500, 0.0800], device='cuda:0')\n",
      "loss: 1.5905418395996094\n",
      "loss: 1.5288361310958862\n",
      "loss: 1.4546175003051758\n",
      "loss: 1.3817284107208252\n",
      "loss: 1.318495512008667\n",
      "Track generation: 1200..1504 -> 304-tiles track\n",
      "Current score: -20.39570957095704\n",
      "Total timesteps: 48023\n",
      "tensor([0.2500, 0.0800], device='cuda:0')\n",
      "loss: 0.9204807281494141\n",
      "loss: 0.908490777015686\n",
      "loss: 0.9045758843421936\n",
      "loss: 0.9060911536216736\n",
      "loss: 0.9107625484466553\n",
      "Track generation: 1290..1617 -> 327-tiles track\n",
      "Current score: -25.210122699386528\n",
      "Total timesteps: 48652\n",
      "tensor([0.2500, 0.0800], device='cuda:0')\n",
      "loss: 0.7430419921875\n",
      "loss: 0.7675901651382446\n",
      "loss: 0.7784919738769531\n",
      "loss: 0.7774304151535034\n",
      "loss: 0.7660328149795532\n",
      "Track generation: 1151..1443 -> 292-tiles track\n",
      "Current score: -46.16718213058468\n",
      "Total timesteps: 49142\n",
      "tensor([0.2500, 0.0800], device='cuda:0')\n",
      "loss: 0.5734592080116272\n",
      "loss: 0.5565635561943054\n",
      "loss: 0.5382620096206665\n",
      "loss: 0.5196811556816101\n",
      "loss: 0.5020511746406555\n",
      "Track generation: 1087..1372 -> 285-tiles track\n",
      "Current score: -34.81760563380293\n",
      "Total timesteps: 50142\n",
      "tensor([0.2500, 0.0800], device='cuda:0')\n",
      "loss: 0.8594415783882141\n",
      "loss: 0.8406228423118591\n",
      "loss: 0.8220217227935791\n",
      "loss: 0.8040809631347656\n",
      "loss: 0.7871964573860168\n",
      "Track generation: 1198..1502 -> 304-tiles track\n",
      "Current score: -35.64702970297046\n",
      "Total timesteps: 50877\n",
      "tensor([0.2500, 0.0800], device='cuda:0')\n",
      "loss: 0.5144517421722412\n",
      "loss: 0.49912023544311523\n",
      "loss: 0.48916423320770264\n",
      "loss: 0.4852367341518402\n",
      "loss: 0.48710545897483826\n",
      "Track generation: 970..1223 -> 253-tiles track\n",
      "Current score: -33.189682539682785\n",
      "Total timesteps: 51513\n",
      "tensor([0.2500, 0.0800], device='cuda:0')\n",
      "loss: 0.9558653831481934\n",
      "loss: 0.9717965126037598\n",
      "loss: 0.9651174545288086\n",
      "loss: 0.939903974533081\n",
      "loss: 0.9035148024559021\n",
      "Track generation: 1093..1377 -> 284-tiles track\n",
      "Current score: -16.363604240282505\n",
      "Total timesteps: 52513\n",
      "tensor([0.2500, 0.0800], device='cuda:0')\n",
      "loss: 1.0162711143493652\n",
      "loss: 0.9831040501594543\n",
      "loss: 0.9519447684288025\n",
      "loss: 0.923976719379425\n",
      "loss: 0.8998178243637085\n",
      "Track generation: 1056..1324 -> 268-tiles track\n",
      "Current score: -7.956179775280905\n",
      "Total timesteps: 53136\n",
      "tensor([0.2500, 0.0800], device='cuda:0')\n",
      "loss: 1.1963874101638794\n",
      "loss: 1.190099835395813\n",
      "loss: 1.1860880851745605\n",
      "loss: 1.183668851852417\n",
      "loss: 1.182380199432373\n",
      "Track generation: 943..1189 -> 246-tiles track\n",
      "Current score: 11.709183673468555\n",
      "Total timesteps: 53652\n",
      "tensor([0.2500, 0.0800], device='cuda:0')\n",
      "loss: 1.7640968561172485\n",
      "loss: 1.7482432126998901\n",
      "loss: 1.733222484588623\n",
      "loss: 1.7192769050598145\n",
      "loss: 1.7065389156341553\n",
      "Track generation: 1241..1555 -> 314-tiles track\n",
      "Current score: -42.4011182108629\n",
      "Total timesteps: 54504\n",
      "tensor([0.2500, 0.0800], device='cuda:0')\n",
      "loss: 0.9574851989746094\n",
      "loss: 0.9781824946403503\n",
      "loss: 0.9869208335876465\n",
      "loss: 0.9853936433792114\n",
      "loss: 0.974848210811615\n",
      "Track generation: 1178..1477 -> 299-tiles track\n",
      "Current score: -21.021476510067075\n",
      "Total timesteps: 55244\n",
      "tensor([0.2500, 0.0800], device='cuda:0')\n",
      "loss: 1.058200716972351\n",
      "loss: 1.0326954126358032\n",
      "loss: 1.0005038976669312\n",
      "loss: 0.9623869061470032\n",
      "loss: 0.9188570976257324\n",
      "Track generation: 1135..1423 -> 288-tiles track\n",
      "Current score: -13.738153310104408\n",
      "Total timesteps: 55601\n",
      "tensor([0.2500, 0.0800], device='cuda:0')\n",
      "loss: 0.9472715258598328\n",
      "loss: 0.9434176087379456\n",
      "loss: 0.9422218203544617\n",
      "loss: 0.9432558417320251\n",
      "loss: 0.9459418058395386\n",
      "Track generation: 1189..1490 -> 301-tiles track\n",
      "Current score: -59.40000000000059\n",
      "Total timesteps: 56156\n",
      "tensor([0.2500, 0.0800], device='cuda:0')\n",
      "loss: 0.5444116592407227\n",
      "loss: 0.5167155861854553\n",
      "loss: 0.4878779351711273\n",
      "loss: 0.4603147804737091\n",
      "loss: 0.436750203371048\n",
      "Track generation: 1211..1518 -> 307-tiles track\n",
      "Current score: -31.37254901960788\n",
      "Total timesteps: 57142\n",
      "tensor([0.2500, 0.0800], device='cuda:0')\n",
      "loss: 0.8694889545440674\n",
      "loss: 0.9053047299385071\n",
      "loss: 0.9196805953979492\n",
      "loss: 0.9095372557640076\n",
      "loss: 0.8811196088790894\n",
      "Track generation: 982..1237 -> 255-tiles track\n",
      "Current score: -36.80393700787417\n",
      "Total timesteps: 58142\n",
      "tensor([0.2500, 0.0800], device='cuda:0')\n",
      "loss: 0.46174147725105286\n",
      "loss: 0.47628384828567505\n",
      "loss: 0.48134148120880127\n",
      "loss: 0.5057411789894104\n",
      "loss: 0.49747058749198914\n",
      "Track generation: 1111..1393 -> 282-tiles track\n",
      "Current score: 10.867971530248777\n",
      "Total timesteps: 58814\n",
      "tensor([0.2500, 0.0800], device='cuda:0')\n",
      "loss: 2.154618978500366\n",
      "loss: 2.172788381576538\n",
      "loss: 2.1796536445617676\n",
      "loss: 2.1239452362060547\n",
      "loss: 2.1468329429626465\n",
      "Track generation: 1119..1410 -> 291-tiles track\n",
      "Current score: -17.118965517241254\n",
      "Total timesteps: 59578\n",
      "tensor([0.2500, 0.0800], device='cuda:0')\n",
      "loss: 0.817794919013977\n",
      "loss: 0.8710994124412537\n",
      "loss: 0.8181344270706177\n",
      "loss: 0.834233820438385\n",
      "loss: 0.8203650116920471\n",
      "Track generation: 1088..1364 -> 276-tiles track\n",
      "Current score: 4.699999999999598\n",
      "Total timesteps: 60124\n",
      "tensor([0.2500, 0.0800], device='cuda:0')\n",
      "loss: 1.576614499092102\n",
      "loss: 1.572754979133606\n",
      "loss: 1.5608919858932495\n",
      "loss: 1.552981972694397\n",
      "loss: 1.5458433628082275\n",
      "Track generation: 1116..1403 -> 287-tiles track\n",
      "Current score: -23.89545454545452\n",
      "Total timesteps: 60870\n",
      "tensor([0.2500, 0.0800], device='cuda:0')\n",
      "loss: 0.6728634834289551\n",
      "loss: 0.676558256149292\n",
      "loss: 0.679840087890625\n",
      "loss: 0.6825300455093384\n",
      "loss: 0.6845943331718445\n",
      "Track generation: 1080..1363 -> 283-tiles track\n",
      "Current score: -21.98581560283692\n",
      "Total timesteps: 61559\n",
      "tensor([0.2500, 0.0800], device='cuda:0')\n",
      "loss: 0.6874188184738159\n",
      "loss: 0.6854150295257568\n",
      "loss: 0.683048665523529\n",
      "loss: 0.6804702877998352\n",
      "loss: 0.6778131723403931\n",
      "Track generation: 1240..1563 -> 323-tiles track\n",
      "Current score: -17.460869565217294\n",
      "Total timesteps: 62559\n",
      "tensor([0.2500, 0.0800], device='cuda:0')\n",
      "loss: 0.988610565662384\n",
      "loss: 0.9918291568756104\n",
      "loss: 0.9897436499595642\n",
      "loss: 0.9829488396644592\n",
      "loss: 0.9719936847686768\n",
      "Track generation: 1237..1553 -> 316-tiles track\n",
      "retry to generate track (normal if there are not manyinstances of this message)\n",
      "Track generation: 1290..1617 -> 327-tiles track\n"
     ]
    }
   ],
   "source": [
    "train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}
{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python388jvsc74a57bd08420e9e93c695d97be91f5272eab9214f2b8a154faa67cd6133f765f4ca85a58",
   "display_name": "Python 3.8.8 64-bit"
  },
  "metadata": {
   "interpreter": {
    "hash": "8420e9e93c695d97be91f5272eab9214f2b8a154faa67cd6133f765f4ca85a58"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "d:\\documents francis\\université\\session8\\inf8225\\projet\\gym\\gym\\logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n  warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    }
   ],
   "source": [
    "import gym\n",
    "from scipy.stats import multivariate_normal\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.distributions import MultivariateNormal\n",
    "import numpy as np\n",
    "from collections import deque\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "env = gym.make('CarRacing-v0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN_Network(nn.Module):\n",
    "    def __init__(self, output_size):\n",
    "        super(CNN_Network, self).__init__()\n",
    "\n",
    "        self.conv2d_0 = nn.Conv2d(1, 8, kernel_size=4, stride=2)\n",
    "        self.relu_0 = nn.LeakyReLU()\n",
    "\n",
    "        self.conv2d_1 = nn.Conv2d(8, 16, kernel_size=3, stride=2)\n",
    "        self.relu_1 = nn.LeakyReLU()\n",
    "\n",
    "        self.conv2d_2 = nn.Conv2d(16, 32, kernel_size=3, stride=2)\n",
    "        self.relu_2 = nn.LeakyReLU()\n",
    "\n",
    "        self.conv2d_3 = nn.Conv2d(32, 64, kernel_size=3, stride=2)\n",
    "        self.relu_3 = nn.LeakyReLU()\n",
    "\n",
    "        self.conv2d_4 = nn.Conv2d(64, 128, kernel_size=3, stride=2, padding=1)\n",
    "        self.relu_4 = nn.LeakyReLU()\n",
    "\n",
    "        self.conv2d_5 = nn.Conv2d(128, 256, kernel_size=3, stride=2)\n",
    "        self.relu_5 = nn.LeakyReLU()\n",
    "\n",
    "        self.action_linear_1 = nn.Linear(4608, 256)\n",
    "        self.relu_action_1 = nn.LeakyReLU()\n",
    "        self.action_linear_2 = nn.Linear(256, output_size)\n",
    "        self.activation_action1 = nn.Tanh()\n",
    "        self.activation_action2 = nn.ReLU()\n",
    "\n",
    "        self.value_linear_1 = nn.Linear(4608, 256)\n",
    "        self.relu_value_1 = nn.LeakyReLU()\n",
    "        self.value_linear_2 = nn.Linear(256, 1)\n",
    "\n",
    "        for layer in [self.conv2d_0 , self.conv2d_1,self.conv2d_3, self.conv2d_4, self.action_linear_1, self.action_linear_2, self.value_linear_1, self.value_linear_2]:\n",
    "            torch.nn.init.xavier_normal_(layer.weight)\n",
    "            torch.nn.init.zeros_(layer.bias)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.relu_0(self.conv2d_0(x))\n",
    "        x = self.relu_1(self.conv2d_1(x))\n",
    "        x = self.relu_2(self.conv2d_2(x))\n",
    "        x = self.relu_3(self.conv2d_3(x))\n",
    "        x = self.relu_4(self.conv2d_4(x))\n",
    "        x = self.relu_5(self.conv2d_5(x))\n",
    "        x = x.view(x.shape[0], -1)\n",
    "\n",
    "        # x_action = self.action_linear_1(x)\n",
    "        x_action = self.action_linear_2(x)\n",
    "        # x_action = self.activation_action1(x_action)\n",
    "\n",
    "        # x_value = self.relu_value_1(self.value_linear_1(x))\n",
    "        x_value = self.value_linear_2(x)\n",
    "        return x_action, x_value\n",
    "\n",
    "agent = CNN_Network(3).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "CNN_Network(\n  (conv2d_0): Conv2d(1, 8, kernel_size=(4, 4), stride=(2, 2))\n  (relu_0): LeakyReLU(negative_slope=0.01)\n  (conv2d_1): Conv2d(8, 16, kernel_size=(3, 3), stride=(2, 2))\n  (relu_1): LeakyReLU(negative_slope=0.01)\n  (conv2d_2): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2))\n  (relu_2): LeakyReLU(negative_slope=0.01)\n  (conv2d_3): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2))\n  (relu_3): LeakyReLU(negative_slope=0.01)\n  (conv2d_4): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n  (relu_4): LeakyReLU(negative_slope=0.01)\n  (conv2d_5): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2))\n  (relu_5): LeakyReLU(negative_slope=0.01)\n  (action_linear_1): Linear(in_features=4608, out_features=256, bias=True)\n  (relu_action_1): LeakyReLU(negative_slope=0.01)\n  (action_linear_2): Linear(in_features=256, out_features=3, bias=True)\n  (activation_action1): Tanh()\n  (activation_action2): ReLU()\n  (value_linear_1): Linear(in_features=4608, out_features=256, bias=True)\n  (relu_value_1): LeakyReLU(negative_slope=0.01)\n  (value_linear_2): Linear(in_features=256, out_features=1, bias=True)\n)\n"
     ]
    }
   ],
   "source": [
    "print(agent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# class OrnsteinUhlenbeckActionNoise():\n",
    "#     def __init__(self, mu, sigma=0.3, theta=.10, dt=1e-2, x0=None):\n",
    "#         self.theta = theta\n",
    "#         self.mu = mu\n",
    "#         self.sigma = sigma\n",
    "#         self.dt = dt\n",
    "#         self.x0 = x0\n",
    "#         self.reset()\n",
    "\n",
    "#     def __call__(self):\n",
    "#         x = self.x_prev + self.theta * (self.mu - self.x_prev) * self.dt + \\\n",
    "#                 self.sigma * self.dt**(1/2) * torch.normal(mean=0.0, std=1.0, size=self.mu.shape, device=device)\n",
    "#         self.x_prev = x\n",
    "#         return x\n",
    "\n",
    "#     def reset(self):\n",
    "#         self.x_prev = self.x0 if self.x0 is not None else torch.zeros_like(self.mu, device=device)\n",
    "\n",
    "#     def __repr__(self):\n",
    "#         return 'OrnsteinUhlenbeckActionNoise(mu={}, sigma={})'.format(self.mu, self.sigma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_torch(tensor):\n",
    "    return torch.tensor(tensor.copy(), dtype=torch.float32, device=device)\n",
    "\n",
    "cov_exploration_matrix = torch.tensor([0.5, 0.1, 0.02], device=device)\n",
    "cov_mat = torch.diag(cov_exploration_matrix)\n",
    "def get_action(state):\n",
    "    actions, values = agent(state)\n",
    "    actions = actions[0]\n",
    "    distribution = MultivariateNormal(actions, cov_mat)\n",
    "    actions_with_exploration = distribution.sample()\n",
    "    log_actions = distribution.log_prob(actions_with_exploration)\n",
    "\n",
    "    return actions_with_exploration.cpu().numpy(), log_actions.cpu().numpy()\n",
    "\n",
    "GAMMA = 0.99\n",
    "def rollout(render, exploration_scale):\n",
    "    global cov_exploration_matrix\n",
    "    base_exploration = [0.2, 0.05, 0.06]\n",
    "    cov_exploration_matrix = torch.tensor(base_exploration, device=device) # * max(exploration_scale, 0.5)\n",
    "\n",
    "    state = env.reset() / 255.\n",
    "    memory = []\n",
    "    timesteps = 0\n",
    "    done = False\n",
    "    streak = 0\n",
    "    while not done:\n",
    "        \n",
    "        action, log_action = get_action(to_torch(state).mean(dim=2).reshape(1, 1, state.shape[0], state.shape[1]))\n",
    "\n",
    "        for i in range(5):\n",
    "            if render or timesteps%100==0:\n",
    "                env.render()\n",
    "            \n",
    "\n",
    "            next_state, reward, done, _ = env.step(action)\n",
    "\n",
    "            if reward < 0:\n",
    "                streak +=1\n",
    "                if streak > 300:\n",
    "                    done = True\n",
    "            else:\n",
    "                streak = 0\n",
    "\n",
    "            # reward += 0.1*np.clip(action[1], 0, 1)\n",
    "\n",
    "            next_state = next_state / 255.\n",
    "            memory.append([state, action, reward, log_action])\n",
    "            timesteps += 1\n",
    "            state = next_state\n",
    "\n",
    "            \n",
    "            if done: \n",
    "                break\n",
    "\n",
    "    states, actions, rewards, log_actions = map(np.array, zip(*memory))\n",
    "\n",
    "    discounted_rewards = np.zeros((len(rewards)))\n",
    "    discount = 0\n",
    "    # Discounts rewards in reverse\n",
    "    for i in reversed(range(len(rewards))):\n",
    "\n",
    "        # Discount fowards from the future for previous states\n",
    "        discount = rewards[i] + discount*GAMMA \n",
    "        discounted_rewards[i] = discount\n",
    "\n",
    "    return to_torch(states).mean(dim=3).unsqueeze(dim=1), to_torch(actions), to_torch(discounted_rewards).reshape(-1,1), to_torch(log_actions), timesteps, np.sum(rewards)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "CLIP_EPSILON = 0.2\n",
    "value_loss_fn = nn.SmoothL1Loss()\n",
    "\n",
    "def get_log_probs_and_value(states, old_actions):\n",
    "    actions, values = agent(states)\n",
    "    distribution = MultivariateNormal(actions, cov_mat)\n",
    "    log_actions = distribution.log_prob(old_actions)\n",
    "\n",
    "    return actions, log_actions, values, distribution.entropy()\n",
    "\n",
    "def compute_advantages(states, rewards):\n",
    "    _, values = agent(states)\n",
    "\n",
    "    advantages = rewards - values.detach()\n",
    "    advantages = (advantages - advantages.mean()) / \\\n",
    "                (advantages.std() + 1e-8) \n",
    "\n",
    "    return advantages\n",
    "\n",
    "def compute_losses(states, actions, rewards, log_actions, advantages):\n",
    "    # Compute policy loss first\n",
    "    # Compute ratios \n",
    "    new_actions, log_new_actions, values, entropy = get_log_probs_and_value(states, actions)\n",
    "    ratios = torch.exp(log_new_actions - log_actions) \n",
    "\n",
    "    policy_loss = torch.min(ratios*advantages, torch.clip(ratios, 1 - CLIP_EPSILON, 1 + CLIP_EPSILON)*advantages)\n",
    "    policy_loss = -torch.mean(policy_loss)\n",
    "\n",
    "    # Compute value loss\n",
    "    value_loss = value_loss_fn(rewards, values)\n",
    "\n",
    "    # Compute entropy loss\n",
    "    entropy_loss = -torch.mean(entropy)\n",
    "    \n",
    "    return policy_loss, value_loss, entropy_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODOS\n",
    "# 1. new_actions / actions - > en log_probs (log_new_actions - log_actions)\n",
    "# 2. Trouver des meilleurs manières pour explorer\n",
    "# 3. tweak value_factor, GAMMA, exploration_factor, lr \n",
    "# 4. Tweak le modèle pytorch, activations\n",
    "\n",
    "\n",
    "def train():\n",
    "    n_time_steps = 1000000\n",
    "    n_updates_per_episode = 5\n",
    "    \n",
    "    value_factor = 0.5\n",
    "    entropy_factor = 0.01\n",
    "\n",
    "    current_time_step = 0\n",
    "    exploration_factor = 0.995\n",
    "\n",
    "    agent_optimizer = optim.Adam(agent.parameters(), lr=0.0001)\n",
    "    scores = []\n",
    "    while current_time_step < n_time_steps:\n",
    "        # try:\n",
    "        with torch.no_grad():\n",
    "            agent.eval()\n",
    "            states, actions, rewards, log_actions, timesteps, episode_score = rollout(len(scores)%5==0, exploration_factor**len(scores))\n",
    "        # except:\n",
    "        #     continue\n",
    "        scores.append(episode_score)\n",
    "        print(f\"Current score: {scores[-1]}\")\n",
    "        print(f\"Total timesteps: {current_time_step}\")\n",
    "        current_time_step += timesteps\n",
    "        print(cov_exploration_matrix)\n",
    "        advantages = compute_advantages(states, rewards)\n",
    "\n",
    "        agent.train()\n",
    "        for _ in range(n_updates_per_episode):\n",
    "            agent_optimizer.zero_grad()\n",
    "            policy_loss, value_loss, entropy_loss = compute_losses(states, actions, rewards, log_actions, advantages)\n",
    "\n",
    "            loss = policy_loss + value_factor*value_loss #+ entropy_factor*entropy_loss\n",
    "            print(f'loss: {loss}')\n",
    "            loss.backward()\n",
    "\n",
    "            agent_optimizer.step()\n",
    "            agent_optimizer.zero_grad()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Track generation: 1183..1483 -> 300-tiles track\n",
      "Current score: -12.704849498327714\n",
      "Total timesteps: 0\n",
      "tensor([0.2000, 0.1000, 0.0600], device='cuda:0')\n",
      "loss: 2.148624897003174\n",
      "loss: 2.1472527980804443\n",
      "loss: 2.145951509475708\n",
      "loss: 2.1446778774261475\n",
      "loss: 2.143397092819214\n",
      "Track generation: 1127..1413 -> 286-tiles track\n",
      "Current score: -5.465789473684211\n",
      "Total timesteps: 740\n",
      "tensor([0.2000, 0.1000, 0.0600], device='cuda:0')\n",
      "loss: 2.0516626834869385\n",
      "loss: 2.051687717437744\n",
      "loss: 2.051703929901123\n",
      "loss: 2.0517232418060303\n",
      "loss: 2.0517373085021973\n",
      "Track generation: 998..1258 -> 260-tiles track\n",
      "Current score: 22.469111969110873\n",
      "Total timesteps: 1520\n",
      "tensor([0.2000, 0.1000, 0.0600], device='cuda:0')\n",
      "loss: 2.9874861240386963\n",
      "loss: 2.9876179695129395\n",
      "loss: 2.987565755844116\n",
      "loss: 2.987384557723999\n",
      "loss: 2.9871139526367188\n",
      "Track generation: 1180..1478 -> 298-tiles track\n",
      "Current score: -14.862962962962877\n",
      "Total timesteps: 2394\n",
      "tensor([0.2000, 0.1000, 0.0600], device='cuda:0')\n",
      "loss: 2.643221378326416\n",
      "loss: 2.642869710922241\n",
      "loss: 2.641711473464966\n",
      "loss: 2.639965057373047\n",
      "loss: 2.6377432346343994\n",
      "Track generation: 1159..1452 -> 293-tiles track\n",
      "Current score: -6.6808219178082915\n",
      "Total timesteps: 2882\n",
      "tensor([0.2000, 0.1000, 0.0600], device='cuda:0')\n",
      "loss: 2.5760481357574463\n",
      "loss: 2.5752029418945312\n",
      "loss: 2.574342966079712\n",
      "loss: 2.57344126701355\n",
      "loss: 2.5725135803222656\n",
      "Track generation: 1261..1580 -> 319-tiles track\n",
      "Current score: -19.90880503144648\n",
      "Total timesteps: 3505\n",
      "tensor([0.2000, 0.1000, 0.0600], device='cuda:0')\n",
      "loss: 2.128643751144409\n",
      "loss: 2.1242215633392334\n",
      "loss: 2.1191177368164062\n",
      "loss: 2.113363742828369\n",
      "loss: 2.1069753170013428\n",
      "Track generation: 1047..1321 -> 274-tiles track\n",
      "Current score: -3.802930402930894\n",
      "Total timesteps: 4050\n",
      "tensor([0.2000, 0.1000, 0.0600], device='cuda:0')\n",
      "loss: 2.7130887508392334\n",
      "loss: 2.708974599838257\n",
      "loss: 2.7044777870178223\n",
      "loss: 2.699556827545166\n",
      "loss: 2.6941192150115967\n",
      "Track generation: 1135..1422 -> 287-tiles track\n",
      "Current score: -4.859440559440593\n",
      "Total timesteps: 4751\n",
      "tensor([0.2000, 0.1000, 0.0600], device='cuda:0')\n",
      "loss: 2.2324886322021484\n",
      "loss: 2.231062889099121\n",
      "loss: 2.2296881675720215\n",
      "loss: 2.2283475399017334\n",
      "loss: 2.2270331382751465\n",
      "Track generation: 988..1245 -> 257-tiles track\n",
      "Current score: 5.206249999999571\n",
      "Total timesteps: 5394\n",
      "tensor([0.2000, 0.1000, 0.0600], device='cuda:0')\n",
      "loss: 3.176154136657715\n",
      "loss: 3.1703922748565674\n",
      "loss: 3.163949966430664\n",
      "loss: 3.1568045616149902\n",
      "loss: 3.1489243507385254\n",
      "Track generation: 897..1133 -> 236-tiles track\n",
      "Current score: -7.691489361702228\n",
      "Total timesteps: 6006\n",
      "tensor([0.2000, 0.1000, 0.0600], device='cuda:0')\n",
      "loss: 2.1112093925476074\n",
      "loss: 2.0970170497894287\n",
      "loss: 2.081540107727051\n",
      "loss: 2.064793348312378\n",
      "loss: 2.0467939376831055\n",
      "Track generation: 1127..1413 -> 286-tiles track\n",
      "Current score: -16.047368421052532\n",
      "Total timesteps: 6551\n",
      "tensor([0.2000, 0.1000, 0.0600], device='cuda:0')\n",
      "loss: 2.2042319774627686\n",
      "loss: 2.1557586193084717\n",
      "loss: 2.103639841079712\n",
      "loss: 2.0474448204040527\n",
      "loss: 1.9870071411132812\n",
      "Track generation: 1049..1316 -> 267-tiles track\n",
      "Current score: 10.363157894735714\n",
      "Total timesteps: 6922\n",
      "tensor([0.2000, 0.1000, 0.0600], device='cuda:0')\n",
      "loss: 2.345820188522339\n",
      "loss: 2.3544700145721436\n",
      "loss: 2.3642680644989014\n",
      "loss: 2.374382495880127\n",
      "loss: 2.383953332901001\n",
      "Track generation: 1076..1358 -> 282-tiles track\n",
      "Current score: -21.647686832740202\n",
      "Total timesteps: 7871\n",
      "tensor([0.2000, 0.1000, 0.0600], device='cuda:0')\n",
      "loss: 1.591227412223816\n",
      "loss: 1.5579514503479004\n",
      "loss: 1.5190751552581787\n",
      "loss: 1.4767934083938599\n",
      "loss: 1.433290958404541\n",
      "Track generation: 1220..1529 -> 309-tiles track\n",
      "Current score: -18.575974025973927\n",
      "Total timesteps: 8293\n",
      "tensor([0.2000, 0.1000, 0.0600], device='cuda:0')\n",
      "loss: 1.5036604404449463\n",
      "loss: 1.4656636714935303\n",
      "loss: 1.4227542877197266\n",
      "loss: 1.394774079322815\n",
      "loss: 1.3531394004821777\n",
      "Track generation: 1087..1363 -> 276-tiles track\n",
      "Current score: -20.799999999999923\n",
      "Total timesteps: 8725\n",
      "tensor([0.2000, 0.1000, 0.0600], device='cuda:0')\n",
      "loss: 1.5115749835968018\n",
      "loss: 1.5069226026535034\n",
      "loss: 1.5005687475204468\n",
      "loss: 1.505811333656311\n",
      "loss: 1.5134159326553345\n",
      "Track generation: 1099..1378 -> 279-tiles track\n",
      "Current score: -21.237410071942428\n",
      "Total timesteps: 9333\n",
      "tensor([0.2000, 0.1000, 0.0600], device='cuda:0')\n",
      "loss: 1.7871923446655273\n",
      "loss: 1.8020951747894287\n",
      "loss: 1.8031578063964844\n",
      "loss: 1.7944525480270386\n",
      "loss: 1.7569947242736816\n",
      "Track generation: 1186..1486 -> 300-tiles track\n",
      "Current score: -36.45484949832821\n",
      "Total timesteps: 10013\n",
      "tensor([0.2000, 0.1000, 0.0600], device='cuda:0')\n",
      "loss: 0.865998387336731\n",
      "loss: 0.7896838188171387\n",
      "loss: 0.7110599875450134\n",
      "loss: 0.6415898203849792\n",
      "loss: 0.5888648629188538\n",
      "Track generation: 1160..1454 -> 294-tiles track\n",
      "Current score: -31.74061433447107\n",
      "Total timesteps: 11013\n",
      "tensor([0.2000, 0.1000, 0.0600], device='cuda:0')\n",
      "loss: 0.9121897220611572\n",
      "loss: 0.8715652227401733\n",
      "loss: 0.8425009250640869\n",
      "loss: 0.8225482702255249\n",
      "loss: 0.8105306625366211\n",
      "Track generation: 1188..1489 -> 301-tiles track\n",
      "Current score: -36.83333333333349\n",
      "Total timesteps: 12013\n",
      "tensor([0.2000, 0.1000, 0.0600], device='cuda:0')\n",
      "loss: 1.2543383836746216\n",
      "loss: 1.2756596803665161\n",
      "loss: 1.292649745941162\n",
      "loss: 1.3056132793426514\n",
      "loss: 1.314792513847351\n",
      "Track generation: 1132..1428 -> 296-tiles track\n",
      "Current score: -35.59322033898363\n",
      "Total timesteps: 12848\n",
      "tensor([0.2000, 0.1000, 0.0600], device='cuda:0')\n",
      "loss: 0.7780353426933289\n",
      "loss: 0.7799047231674194\n",
      "loss: 0.7808529138565063\n",
      "loss: 0.7809258699417114\n",
      "loss: 0.7802035808563232\n",
      "Track generation: 1037..1300 -> 263-tiles track\n",
      "Current score: -29.948854961832176\n",
      "Total timesteps: 13848\n",
      "tensor([0.2000, 0.1000, 0.0600], device='cuda:0')\n",
      "loss: 1.1805620193481445\n",
      "loss: 1.1716878414154053\n",
      "loss: 1.1584559679031372\n",
      "loss: 1.1415799856185913\n",
      "loss: 1.121804118156433\n",
      "Track generation: 1143..1433 -> 290-tiles track\n",
      "Current score: -30.597923875432674\n",
      "Total timesteps: 14491\n",
      "tensor([0.2000, 0.1000, 0.0600], device='cuda:0')\n",
      "loss: 1.0640919208526611\n",
      "loss: 1.0476154088974\n",
      "loss: 1.0317108631134033\n",
      "loss: 1.0168145895004272\n",
      "loss: 1.0036840438842773\n",
      "Track generation: 1093..1378 -> 285-tiles track\n",
      "Current score: -33.09859154929622\n",
      "Total timesteps: 15143\n",
      "tensor([0.2000, 0.1000, 0.0600], device='cuda:0')\n",
      "loss: 0.6670876145362854\n",
      "loss: 0.6689391136169434\n",
      "loss: 0.6726399064064026\n",
      "loss: 0.6773756146430969\n",
      "loss: 0.6823145151138306\n",
      "Track generation: 1288..1614 -> 326-tiles track\n",
      "Current score: -41.538461538462\n",
      "Total timesteps: 16143\n",
      "tensor([0.2000, 0.1000, 0.0600], device='cuda:0')\n",
      "loss: 0.4933731257915497\n",
      "loss: 0.49350088834762573\n",
      "loss: 0.4940730333328247\n",
      "loss: 0.4948963522911072\n",
      "loss: 0.49577659368515015\n",
      "Track generation: 1152..1443 -> 291-tiles track\n",
      "Current score: -42.2172413793106\n",
      "Total timesteps: 17143\n",
      "tensor([0.2000, 0.1000, 0.0600], device='cuda:0')\n",
      "loss: 0.7511914372444153\n",
      "loss: 0.7454497814178467\n",
      "loss: 0.7378113269805908\n",
      "loss: 0.7291011214256287\n",
      "loss: 0.7201470732688904\n",
      "Track generation: 1252..1569 -> 317-tiles track\n",
      "Current score: -43.03797468354483\n",
      "Total timesteps: 17910\n",
      "tensor([0.2000, 0.1000, 0.0600], device='cuda:0')\n",
      "loss: 0.42758506536483765\n",
      "loss: 0.4366210401058197\n",
      "loss: 0.44123324751853943\n",
      "loss: 0.4409003257751465\n",
      "loss: 0.43619707226753235\n",
      "Track generation: 1071..1343 -> 272-tiles track\n",
      "Current score: -47.91955719557244\n",
      "Total timesteps: 18910\n",
      "tensor([0.2000, 0.1000, 0.0600], device='cuda:0')\n",
      "loss: 0.7002575397491455\n",
      "loss: 0.7014513611793518\n",
      "loss: 0.7026124596595764\n",
      "loss: 0.7035651206970215\n",
      "loss: 0.7041979432106018\n",
      "Track generation: 1294..1622 -> 328-tiles track\n",
      "Current score: -38.83792048929753\n",
      "Total timesteps: 19832\n",
      "tensor([0.2000, 0.1000, 0.0600], device='cuda:0')\n",
      "loss: 0.8562184572219849\n",
      "loss: 0.8504141569137573\n",
      "loss: 0.8410845398902893\n",
      "loss: 0.8296909332275391\n",
      "loss: 0.8176497220993042\n",
      "Track generation: 1081..1355 -> 274-tiles track\n",
      "Current score: -26.73992673992706\n",
      "Total timesteps: 20832\n",
      "tensor([0.2000, 0.1000, 0.0600], device='cuda:0')\n",
      "loss: 0.7990565299987793\n",
      "loss: 0.7612541913986206\n",
      "loss: 0.7212645411491394\n",
      "loss: 0.6831275820732117\n",
      "loss: 0.6495537757873535\n",
      "Track generation: 1135..1431 -> 296-tiles track\n",
      "Current score: -45.32203389830561\n",
      "Total timesteps: 21832\n",
      "tensor([0.2000, 0.1000, 0.0600], device='cuda:0')\n",
      "loss: 0.9676198363304138\n",
      "loss: 0.9964507818222046\n",
      "loss: 1.016696810722351\n",
      "loss: 1.029532551765442\n",
      "loss: 1.033009648323059\n",
      "Track generation: 1087..1363 -> 276-tiles track\n",
      "Current score: -52.72727272727355\n",
      "Total timesteps: 22692\n",
      "tensor([0.2000, 0.1000, 0.0600], device='cuda:0')\n",
      "loss: 0.8854935169219971\n",
      "loss: 0.8699571490287781\n",
      "loss: 0.8441309332847595\n",
      "loss: 0.8097123503684998\n",
      "loss: 0.768530547618866\n",
      "Track generation: 1235..1548 -> 313-tiles track\n",
      "Current score: -42.30769230769277\n",
      "Total timesteps: 23692\n",
      "tensor([0.2000, 0.1000, 0.0600], device='cuda:0')\n",
      "loss: 1.0403916835784912\n",
      "loss: 1.0095243453979492\n",
      "loss: 0.9793862700462341\n",
      "loss: 0.9510247707366943\n",
      "loss: 0.9265176653862\n",
      "Track generation: 1167..1465 -> 298-tiles track\n",
      "retry to generate track (normal if there are not manyinstances of this message)\n",
      "Track generation: 1024..1291 -> 267-tiles track\n",
      "Current score: -42.38421052631606\n",
      "Total timesteps: 24692\n",
      "tensor([0.2000, 0.1000, 0.0600], device='cuda:0')\n",
      "loss: 0.9541844129562378\n",
      "loss: 0.8891826272010803\n",
      "loss: 0.8224679231643677\n",
      "loss: 0.7584422826766968\n",
      "loss: 0.7018380761146545\n",
      "Track generation: 1199..1503 -> 304-tiles track\n",
      "Current score: -60.39603960396114\n",
      "Total timesteps: 25379\n",
      "tensor([0.2000, 0.1000, 0.0600], device='cuda:0')\n",
      "loss: 0.49101459980010986\n",
      "loss: 0.5113663077354431\n",
      "loss: 0.5424261689186096\n",
      "loss: 0.5739321708679199\n",
      "loss: 0.59723961353302\n",
      "Track generation: 1133..1420 -> 287-tiles track\n",
      "Current score: -58.04195804195864\n",
      "Total timesteps: 26379\n",
      "tensor([0.2000, 0.1000, 0.0600], device='cuda:0')\n",
      "loss: 0.8561884164810181\n",
      "loss: 0.8523061871528625\n",
      "loss: 0.8367785215377808\n",
      "loss: 0.814155101776123\n",
      "loss: 0.7865565419197083\n",
      "Track generation: 1210..1517 -> 307-tiles track\n",
      "Current score: -47.71241830065429\n",
      "Total timesteps: 27379\n",
      "tensor([0.2000, 0.1000, 0.0600], device='cuda:0')\n",
      "loss: 0.9006500244140625\n",
      "loss: 0.8239795565605164\n",
      "loss: 0.7467305064201355\n",
      "loss: 0.6779313087463379\n",
      "loss: 0.6237461566925049\n",
      "Track generation: 1180..1479 -> 299-tiles track\n",
      "Current score: -19.4630872483228\n",
      "Total timesteps: 28379\n",
      "tensor([0.2000, 0.1000, 0.0600], device='cuda:0')\n",
      "loss: 1.740831732749939\n",
      "loss: 1.6703088283538818\n",
      "loss: 1.6118096113204956\n",
      "loss: 1.565562129020691\n",
      "loss: 1.5299866199493408\n",
      "Track generation: 1127..1413 -> 286-tiles track\n",
      "Current score: -25.829824561403605\n",
      "Total timesteps: 29379\n",
      "tensor([0.2000, 0.1000, 0.0600], device='cuda:0')\n",
      "loss: 1.1213462352752686\n",
      "loss: 1.1366480588912964\n",
      "loss: 1.1518571376800537\n",
      "loss: 1.1659655570983887\n",
      "loss: 1.1784833669662476\n",
      "Track generation: 1235..1548 -> 313-tiles track\n",
      "Current score: -48.7179487179495\n",
      "Total timesteps: 29918\n",
      "tensor([0.2000, 0.1000, 0.0600], device='cuda:0')\n",
      "loss: 0.7104738354682922\n",
      "loss: 0.7228655815124512\n",
      "loss: 0.7273777723312378\n",
      "loss: 0.7248037457466125\n",
      "loss: 0.7160150408744812\n",
      "Track generation: 1196..1499 -> 303-tiles track\n",
      "Current score: -60.26490066225246\n",
      "Total timesteps: 30918\n",
      "tensor([0.2000, 0.1000, 0.0600], device='cuda:0')\n",
      "loss: 1.1789641380310059\n",
      "loss: 1.1497395038604736\n",
      "loss: 1.111842155456543\n",
      "loss: 1.0671417713165283\n",
      "loss: 1.0163980722427368\n",
      "Track generation: 1111..1393 -> 282-tiles track\n",
      "Current score: -57.29537366548128\n",
      "Total timesteps: 31918\n",
      "tensor([0.2000, 0.1000, 0.0600], device='cuda:0')\n",
      "loss: 0.8644987344741821\n",
      "loss: 0.812274158000946\n",
      "loss: 0.7592645287513733\n",
      "loss: 0.7078776955604553\n",
      "loss: 0.6590895652770996\n",
      "Track generation: 1155..1454 -> 299-tiles track\n",
      "Current score: -26.832885906040374\n",
      "Total timesteps: 32918\n",
      "tensor([0.2000, 0.1000, 0.0600], device='cuda:0')\n",
      "loss: 1.0593441724777222\n",
      "loss: 0.9856506586074829\n",
      "loss: 0.9113751649856567\n",
      "loss: 0.838560938835144\n",
      "loss: 0.7712084054946899\n",
      "Track generation: 1090..1372 -> 282-tiles track\n",
      "Current score: -53.73665480427123\n",
      "Total timesteps: 33287\n",
      "tensor([0.2000, 0.1000, 0.0600], device='cuda:0')\n",
      "loss: 0.6191522479057312\n",
      "loss: 0.6853775978088379\n",
      "loss: 0.7392944693565369\n",
      "loss: 0.7703330516815186\n",
      "loss: 0.779120147228241\n",
      "Track generation: 1077..1350 -> 273-tiles track\n",
      "Current score: -54.835294117647756\n",
      "Total timesteps: 34287\n",
      "tensor([0.2000, 0.1000, 0.0600], device='cuda:0')\n",
      "loss: 0.6994256973266602\n",
      "loss: 0.6880651712417603\n",
      "loss: 0.670390784740448\n",
      "loss: 0.656623125076294\n",
      "loss: 0.6406885981559753\n",
      "Track generation: 1067..1344 -> 277-tiles track\n",
      "Current score: -31.15942028985564\n",
      "Total timesteps: 35203\n",
      "tensor([0.2000, 0.1000, 0.0600], device='cuda:0')\n",
      "loss: 1.4171497821807861\n",
      "loss: 1.3264412879943848\n",
      "loss: 1.2135037183761597\n",
      "loss: 1.0953525304794312\n",
      "loss: 0.9796431660652161\n",
      "Track generation: 1031..1293 -> 262-tiles track\n",
      "Current score: -46.3601532567056\n",
      "Total timesteps: 36203\n",
      "tensor([0.2000, 0.1000, 0.0600], device='cuda:0')\n",
      "loss: 0.6057808995246887\n",
      "loss: 0.6027523875236511\n",
      "loss: 0.6095531582832336\n",
      "loss: 0.6222462058067322\n",
      "loss: 0.6377189755439758\n",
      "Track generation: 1217..1527 -> 310-tiles track\n",
      "Current score: -49.4375404530749\n",
      "Total timesteps: 37203\n",
      "tensor([0.2000, 0.1000, 0.0600], device='cuda:0')\n",
      "loss: 0.8474318981170654\n",
      "loss: 0.8737146258354187\n",
      "loss: 0.8902175426483154\n",
      "loss: 0.897513210773468\n",
      "loss: 0.8963972926139832\n",
      "Track generation: 1212..1519 -> 307-tiles track\n",
      "Current score: -44.444444444445\n",
      "Total timesteps: 38021\n",
      "tensor([0.2000, 0.1000, 0.0600], device='cuda:0')\n",
      "loss: 0.5581839680671692\n",
      "loss: 0.5541495680809021\n",
      "loss: 0.5497246384620667\n",
      "loss: 0.5453141927719116\n",
      "loss: 0.5410633087158203\n",
      "Track generation: 1146..1437 -> 291-tiles track\n",
      "Current score: -65.51724137931116\n",
      "Total timesteps: 39021\n",
      "tensor([0.2000, 0.1000, 0.0600], device='cuda:0')\n",
      "loss: 0.904718816280365\n",
      "loss: 0.8748049736022949\n",
      "loss: 0.836000382900238\n",
      "loss: 0.7898989319801331\n",
      "loss: 0.7383725643157959\n",
      "Track generation: 1098..1382 -> 284-tiles track\n",
      "Current score: -57.59717314487733\n",
      "Total timesteps: 40021\n",
      "tensor([0.2000, 0.1000, 0.0600], device='cuda:0')\n",
      "loss: 0.8298918008804321\n",
      "loss: 0.8098596334457397\n",
      "loss: 0.7938543558120728\n",
      "loss: 0.7820301055908203\n",
      "loss: 0.7746847867965698\n",
      "Track generation: 1200..1504 -> 304-tiles track\n",
      "Current score: -30.197689768977007\n",
      "Total timesteps: 41021\n",
      "tensor([0.2000, 0.1000, 0.0600], device='cuda:0')\n",
      "loss: 0.8567403554916382\n",
      "loss: 0.8311774730682373\n",
      "loss: 0.8078423738479614\n",
      "loss: 0.7878464460372925\n",
      "loss: 0.7720917463302612\n",
      "Track generation: 1228..1539 -> 311-tiles track\n",
      "Current score: -67.74193548387134\n",
      "Total timesteps: 41554\n",
      "tensor([0.2000, 0.1000, 0.0600], device='cuda:0')\n",
      "loss: 0.5497767925262451\n",
      "loss: 0.5390493273735046\n",
      "loss: 0.5357922911643982\n",
      "loss: 0.5392096638679504\n",
      "loss: 0.5473306179046631\n",
      "Track generation: 1269..1590 -> 321-tiles track\n",
      "Current score: -71.87500000000013\n",
      "Total timesteps: 42554\n",
      "tensor([0.2000, 0.1000, 0.0600], device='cuda:0')\n",
      "loss: 0.556583821773529\n",
      "loss: 0.5583270192146301\n",
      "loss: 0.5614076256752014\n",
      "loss: 0.5648676753044128\n",
      "loss: 0.5678290724754333\n",
      "Track generation: 1078..1354 -> 276-tiles track\n",
      "retry to generate track (normal if there are not manyinstances of this message)\n",
      "Track generation: 1158..1433 -> 275-tiles track\n",
      "retry to generate track (normal if there are not manyinstances of this message)\n",
      "Track generation: 1161..1463 -> 302-tiles track\n",
      "Current score: -66.77740863787432\n",
      "Total timesteps: 43554\n",
      "tensor([0.2000, 0.1000, 0.0600], device='cuda:0')\n",
      "loss: 0.5293728113174438\n",
      "loss: 0.5275356769561768\n",
      "loss: 0.5210816860198975\n",
      "loss: 0.5118094086647034\n",
      "loss: 0.5020968914031982\n",
      "Track generation: 1382..1732 -> 350-tiles track\n",
      "Current score: -71.3467048710605\n",
      "Total timesteps: 44554\n",
      "tensor([0.2000, 0.1000, 0.0600], device='cuda:0')\n",
      "loss: 0.6555370688438416\n",
      "loss: 0.6473884582519531\n",
      "loss: 0.64130038022995\n",
      "loss: 0.6374677419662476\n",
      "loss: 0.6357369422912598\n",
      "Track generation: 1157..1450 -> 293-tiles track\n",
      "Current score: -69.17808219178141\n",
      "Total timesteps: 45554\n",
      "tensor([0.2000, 0.1000, 0.0600], device='cuda:0')\n",
      "loss: 0.4331459701061249\n",
      "loss: 0.4314640760421753\n",
      "loss: 0.43152937293052673\n",
      "loss: 0.4328085482120514\n",
      "loss: 0.43470466136932373\n",
      "Track generation: 1192..1494 -> 302-tiles track\n",
      "Current score: -56.81063122923668\n",
      "Total timesteps: 46554\n",
      "tensor([0.2000, 0.1000, 0.0600], device='cuda:0')\n",
      "loss: 0.611721396446228\n",
      "loss: 0.6010422110557556\n",
      "loss: 0.5887621641159058\n",
      "loss: 0.57648766040802\n",
      "loss: 0.5655261874198914\n",
      "Track generation: 1335..1673 -> 338-tiles track\n",
      "Current score: -61.424332344214555\n",
      "Total timesteps: 47554\n",
      "tensor([0.2000, 0.1000, 0.0600], device='cuda:0')\n",
      "loss: 0.49445390701293945\n",
      "loss: 0.49913346767425537\n",
      "loss: 0.5042418241500854\n",
      "loss: 0.5087202787399292\n",
      "loss: 0.5118860006332397\n",
      "Track generation: 1179..1478 -> 299-tiles track\n",
      "Current score: -36.69865771812099\n",
      "Total timesteps: 48554\n",
      "tensor([0.2000, 0.1000, 0.0600], device='cuda:0')\n",
      "loss: 0.725975513458252\n",
      "loss: 0.7260122895240784\n",
      "loss: 0.7260644435882568\n",
      "loss: 0.7261214852333069\n",
      "loss: 0.7261743545532227\n",
      "Track generation: 1133..1420 -> 287-tiles track\n",
      "Current score: -51.04895104895198\n",
      "Total timesteps: 49223\n",
      "tensor([0.2000, 0.1000, 0.0600], device='cuda:0')\n",
      "loss: 0.7452195286750793\n",
      "loss: 0.7433699369430542\n",
      "loss: 0.7405061721801758\n",
      "loss: 0.7369819283485413\n",
      "loss: 0.7331475019454956\n",
      "Track generation: 1235..1548 -> 313-tiles track\n",
      "Current score: -34.85384615384634\n",
      "Total timesteps: 50223\n",
      "tensor([0.2000, 0.1000, 0.0600], device='cuda:0')\n",
      "loss: 0.781803548336029\n",
      "loss: 0.781339704990387\n",
      "loss: 0.7811899185180664\n",
      "loss: 0.7812772989273071\n",
      "loss: 0.7815268039703369\n",
      "Track generation: 1113..1397 -> 284-tiles track\n",
      "retry to generate track (normal if there are not manyinstances of this message)\n",
      "Track generation: 1248..1564 -> 316-tiles track\n",
      "Current score: -50.804761904762316\n",
      "Total timesteps: 50860\n",
      "tensor([0.2000, 0.1000, 0.0600], device='cuda:0')\n",
      "loss: 0.9386073350906372\n",
      "loss: 0.9399985671043396\n",
      "loss: 0.9401987791061401\n",
      "loss: 0.939363956451416\n",
      "loss: 0.9376254081726074\n",
      "Track generation: 1048..1314 -> 266-tiles track\n",
      "Current score: -40.23773584905683\n",
      "Total timesteps: 51749\n",
      "tensor([0.2000, 0.1000, 0.0600], device='cuda:0')\n",
      "loss: 0.7923080921173096\n",
      "loss: 0.7902950048446655\n",
      "loss: 0.7882136106491089\n",
      "loss: 0.7861751317977905\n",
      "loss: 0.7842743396759033\n",
      "Track generation: 1143..1433 -> 290-tiles track\n",
      "Current score: -29.778546712802918\n",
      "Total timesteps: 52491\n",
      "tensor([0.2000, 0.1000, 0.0600], device='cuda:0')\n",
      "loss: 0.8914409279823303\n",
      "loss: 0.892401933670044\n",
      "loss: 0.8932929635047913\n",
      "loss: 0.8940313458442688\n",
      "loss: 0.8945702314376831\n",
      "Track generation: 1304..1635 -> 331-tiles track\n",
      "Current score: -63.63636363636459\n",
      "Total timesteps: 53031\n",
      "tensor([0.2000, 0.1000, 0.0600], device='cuda:0')\n",
      "loss: 0.49321338534355164\n",
      "loss: 0.4914911091327667\n",
      "loss: 0.4891227185726166\n",
      "loss: 0.4864276945590973\n",
      "loss: 0.483722448348999\n",
      "Track generation: 1188..1489 -> 301-tiles track\n",
      "Current score: -41.700000000000294\n",
      "Total timesteps: 54031\n",
      "tensor([0.2000, 0.1000, 0.0600], device='cuda:0')\n",
      "loss: 0.637230396270752\n",
      "loss: 0.6289287805557251\n",
      "loss: 0.6200006604194641\n",
      "loss: 0.6113219261169434\n",
      "loss: 0.6037415266036987\n",
      "Track generation: 951..1197 -> 246-tiles track\n",
      "Current score: -59.183673469388616\n",
      "Total timesteps: 54648\n",
      "tensor([0.2000, 0.1000, 0.0600], device='cuda:0')\n",
      "loss: 0.718588650226593\n",
      "loss: 0.7226647138595581\n",
      "loss: 0.7265517711639404\n",
      "loss: 0.7297550439834595\n",
      "loss: 0.7319445610046387\n",
      "Track generation: 1084..1359 -> 275-tiles track\n",
      "Current score: -63.503649635037235\n",
      "Total timesteps: 55648\n",
      "tensor([0.2000, 0.1000, 0.0600], device='cuda:0')\n",
      "loss: 0.5262251496315002\n",
      "loss: 0.5263997912406921\n",
      "loss: 0.5261770486831665\n",
      "loss: 0.525627851486206\n",
      "loss: 0.5248610973358154\n",
      "Track generation: 1055..1323 -> 268-tiles track\n",
      "Current score: -33.37340823970053\n",
      "Total timesteps: 56648\n",
      "tensor([0.2000, 0.1000, 0.0600], device='cuda:0')\n",
      "loss: 0.7485594153404236\n",
      "loss: 0.7477902770042419\n",
      "loss: 0.7470908761024475\n",
      "loss: 0.7465038895606995\n",
      "loss: 0.7460533380508423\n",
      "Track generation: 1173..1470 -> 297-tiles track\n",
      "Current score: -69.5945945945949\n",
      "Total timesteps: 57169\n",
      "tensor([0.2000, 0.1000, 0.0600], device='cuda:0')\n",
      "loss: 0.6117101311683655\n",
      "loss: 0.6124047040939331\n",
      "loss: 0.610690712928772\n",
      "loss: 0.607011079788208\n",
      "loss: 0.6019912362098694\n",
      "Track generation: 1147..1438 -> 291-tiles track\n",
      "Current score: -62.068965517242276\n",
      "Total timesteps: 58169\n",
      "tensor([0.2000, 0.1000, 0.0600], device='cuda:0')\n",
      "loss: 0.5137327313423157\n",
      "loss: 0.5174320340156555\n",
      "loss: 0.5192872881889343\n",
      "loss: 0.5191199779510498\n",
      "loss: 0.517155110836029\n",
      "Track generation: 1111..1393 -> 282-tiles track\n",
      "Current score: -60.854092526691296\n",
      "Total timesteps: 59169\n",
      "tensor([0.2000, 0.1000, 0.0600], device='cuda:0')\n",
      "loss: 0.5436533689498901\n",
      "loss: 0.5394127368927002\n",
      "loss: 0.5350946187973022\n",
      "loss: 0.5312755107879639\n",
      "loss: 0.5283303260803223\n",
      "Track generation: 1164..1459 -> 295-tiles track\n",
      "Current score: -59.18367346938862\n",
      "Total timesteps: 60169\n",
      "tensor([0.2000, 0.1000, 0.0600], device='cuda:0')\n",
      "loss: 0.5026696920394897\n",
      "loss: 0.500306248664856\n",
      "loss: 0.4990153908729553\n",
      "loss: 0.49868330359458923\n",
      "loss: 0.4990862309932709\n",
      "Track generation: 1204..1509 -> 305-tiles track\n",
      "Current score: -67.10526315789546\n",
      "Total timesteps: 61169\n",
      "tensor([0.2000, 0.1000, 0.0600], device='cuda:0')\n",
      "loss: 0.4417482614517212\n",
      "loss: 0.4443414807319641\n",
      "loss: 0.44421571493148804\n",
      "loss: 0.44165313243865967\n",
      "loss: 0.4372352063655853\n",
      "Track generation: 964..1214 -> 250-tiles track\n",
      "Current score: -55.82329317269165\n",
      "Total timesteps: 62169\n",
      "tensor([0.2000, 0.1000, 0.0600], device='cuda:0')\n",
      "loss: 0.630859911441803\n",
      "loss: 0.6338198781013489\n",
      "loss: 0.635246217250824\n",
      "loss: 0.6350857615470886\n",
      "loss: 0.6335132718086243\n",
      "Track generation: 1211..1518 -> 307-tiles track\n",
      "Current score: -70.28823529411808\n",
      "Total timesteps: 63169\n",
      "tensor([0.2000, 0.1000, 0.0600], device='cuda:0')\n",
      "loss: 0.5439274311065674\n",
      "loss: 0.5401036739349365\n",
      "loss: 0.5263600945472717\n",
      "loss: 0.5051400065422058\n",
      "loss: 0.47949618101119995\n",
      "Track generation: 1096..1374 -> 278-tiles track\n",
      "Current score: -60.28880866426067\n",
      "Total timesteps: 64166\n",
      "tensor([0.2000, 0.1000, 0.0600], device='cuda:0')\n",
      "loss: 0.6916711926460266\n",
      "loss: 0.6873393654823303\n",
      "loss: 0.6870568990707397\n",
      "loss: 0.690168559551239\n",
      "loss: 0.6953408718109131\n",
      "Track generation: 1231..1543 -> 312-tiles track\n",
      "Current score: -63.676527331190464\n",
      "Total timesteps: 65166\n",
      "tensor([0.2000, 0.1000, 0.0600], device='cuda:0')\n",
      "loss: 0.47063568234443665\n",
      "loss: 0.47037938237190247\n",
      "loss: 0.4714091718196869\n",
      "loss: 0.47279033064842224\n",
      "loss: 0.47449737787246704\n",
      "Track generation: 1176..1482 -> 306-tiles track\n",
      "Current score: -73.77049180327896\n",
      "Total timesteps: 66060\n",
      "tensor([0.2000, 0.1000, 0.0600], device='cuda:0')\n",
      "loss: 0.46279239654541016\n",
      "loss: 0.46308204531669617\n",
      "loss: 0.46340495347976685\n",
      "loss: 0.4636692702770233\n",
      "loss: 0.46381258964538574\n",
      "Track generation: 1377..1725 -> 348-tiles track\n",
      "Current score: -74.06340057636908\n",
      "Total timesteps: 67060\n",
      "tensor([0.2000, 0.1000, 0.0600], device='cuda:0')\n",
      "loss: 0.44181472063064575\n",
      "loss: 0.4418121576309204\n",
      "loss: 0.44180914759635925\n"
     ]
    }
   ],
   "source": [
    "train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}